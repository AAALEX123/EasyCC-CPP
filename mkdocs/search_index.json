{
    "docs": [
        {
            "location": "/",
            "text": "EasyCC C++ \n\n\nGithub\n\n\nLink: \nhttps://github.com/amirbawab/EasyCC-CPP\n\n\nAbout\n\n\nEasyCC C++ (Easy Compiler Compiler written in C++) is a library allowing users to easily develop their own programming language. The project does not require wrting any line of code for the lexical and syntax analysis phases. The configurations of the latters are provided as JSON files to the library. Adding the logic for a programming language is done by simply registering semantic action handlers in order to gradually build the structure of the input and eventually generating output code.\n\n\nUsage\n\n\nNote: The library depends on Boost 1.63.0, make sure it is installed before compiling the project (Instructions can be found in \n.travis.yml\n file).\n\n\nCMakeLists.txt\n\n\ncmake_minimum_required(VERSION 3.5)\nproject(myProject)\nset(MYPROJECT_DEV_EXEC \"myproject_dev\")\nset(MYPROJECT_PRO_EXEC \"myproject_pro\")\n\nadd_subdirectory(EasyCC-CPP)\nadd_compile_options(-std=c++11)\n\n# Configure directory of output file\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# Include easycc header files\ninclude_directories(EasyCC-CPP/include)\n\n# Add the executables\nadd_executable(${MYPROJECT_DEV_EXEC} maindev.cpp)\nadd_executable(${MYPROJECT_PRO_EXEC} mainpro.cpp)\n\n# Link library to the executable\ntarget_link_libraries(${MYPROJECT_DEV_EXEC} easyccdev)\ntarget_link_libraries(${MYPROJECT_PRO_EXEC} easyccpro)\n\n\n\n\nFor a full \nCMakeLists.txt\n example, check \nBashClass\n which uses EasyCC C++ library\n\n\nDifference between \neasyccdev\n and \neasyccpro\n libraries\n\n\nBoth libraries use the same Lexical and Syntax algorithms, and switching from one library to another requires minor changes.\n\n\n\n\neasyccdev\n (EasyCC development mode) takes the JSON files as arguments in the final executable. This is useful during the development phase because the program does not need to be recompiled to apply changes in the JSON files.\n\n\neasyccpro\n (EasyCC production mode) takes the JSON files as arguments to the \ncmake\n program. The compile process for your program will be composed of two steps. First is embedding the JSON files into the executable, and  second is compiling your program with the generated files.\n\n\n\n\nContribution\n\n\n\n\nFeel free to contribute",
            "title": "Home"
        },
        {
            "location": "/#easycc-c",
            "text": "",
            "title": "EasyCC C++"
        },
        {
            "location": "/#github",
            "text": "Link:  https://github.com/amirbawab/EasyCC-CPP",
            "title": "Github"
        },
        {
            "location": "/#about",
            "text": "EasyCC C++ (Easy Compiler Compiler written in C++) is a library allowing users to easily develop their own programming language. The project does not require wrting any line of code for the lexical and syntax analysis phases. The configurations of the latters are provided as JSON files to the library. Adding the logic for a programming language is done by simply registering semantic action handlers in order to gradually build the structure of the input and eventually generating output code.",
            "title": "About"
        },
        {
            "location": "/#usage",
            "text": "Note: The library depends on Boost 1.63.0, make sure it is installed before compiling the project (Instructions can be found in  .travis.yml  file).",
            "title": "Usage"
        },
        {
            "location": "/#cmakeliststxt",
            "text": "cmake_minimum_required(VERSION 3.5)\nproject(myProject)\nset(MYPROJECT_DEV_EXEC \"myproject_dev\")\nset(MYPROJECT_PRO_EXEC \"myproject_pro\")\n\nadd_subdirectory(EasyCC-CPP)\nadd_compile_options(-std=c++11)\n\n# Configure directory of output file\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# Include easycc header files\ninclude_directories(EasyCC-CPP/include)\n\n# Add the executables\nadd_executable(${MYPROJECT_DEV_EXEC} maindev.cpp)\nadd_executable(${MYPROJECT_PRO_EXEC} mainpro.cpp)\n\n# Link library to the executable\ntarget_link_libraries(${MYPROJECT_DEV_EXEC} easyccdev)\ntarget_link_libraries(${MYPROJECT_PRO_EXEC} easyccpro)  For a full  CMakeLists.txt  example, check  BashClass  which uses EasyCC C++ library",
            "title": "CMakeLists.txt"
        },
        {
            "location": "/#difference-between-easyccdev-and-easyccpro-libraries",
            "text": "Both libraries use the same Lexical and Syntax algorithms, and switching from one library to another requires minor changes.   easyccdev  (EasyCC development mode) takes the JSON files as arguments in the final executable. This is useful during the development phase because the program does not need to be recompiled to apply changes in the JSON files.  easyccpro  (EasyCC production mode) takes the JSON files as arguments to the  cmake  program. The compile process for your program will be composed of two steps. First is embedding the JSON files into the executable, and  second is compiling your program with the generated files.",
            "title": "Difference between easyccdev and easyccpro libraries"
        },
        {
            "location": "/#contribution",
            "text": "Feel free to contribute",
            "title": "Contribution"
        },
        {
            "location": "/lexical/",
            "text": "Lexical analysis\n\n\nDescription\n\n\nThe lexical analysis is the first phase in compiler design where the user input is scanned and converted \ninto a sequence of tokens. The generated lexical tokens are then provided as input to the syntax analyzer.\n\n\nI - State machine\n\n\nA state machine is a graph composed of vertices connected by edges. The graph has a single starting vertex\nand one or more middle or final tokens. Landing on a final vertex means that a new token is created.\nEdges allow input characters to traverse the graph by assigning a letter label to each edge.  \n\n\nJSON structure\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nstates\n\n        \nList of states/vertices of the state machine\n\n        \nArray of \nstate objects\n\n    \n\n    \n\n        \ntransitions\n\n        \nList of transitions/edges of the state machine\n\n        \nArray of \ntransition objects\n\n    \n\n\n\n\nState object table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \ntype\n\n        \nType of the state\n\n        \nInitial\n\n        \nInitial state. Exactly one state must be marked as initial\n\n        \nYes\n\n    \n\n    \n\n        \nNORMAL\n\n        \nNormal state.\n\n    \n\n    \n\n        \nFINAL\n\n        \nFinal state.\n\n    \n\n    \n\n        \nid\n\n        \nUnique id for each state\n\n        \n0, 1, 2, ...\n\n        \nCounting starts from 0 and should be consecutive\n\n        \nYes\n\n    \n\n    \n\n        \ntoken\n\n        \nName of the token created when landing on a final state\n\n        \nstring (e.g. \nT_SEMICOLON\n)\n\n        \nCannot be a \nreserved lexical keyword\n\n        \nOnly for final states\n\n    \n\n    \n\n        \nbacktrack\n\n        \nBacktrack one character in the user input. This is required when the only possible \n        way to know that the token value has ended is by reading a character that is not part of the token \n        value.\n\n        \nfalse\n\n        \nDo not backtrack\n\n        \nOnly for final states\n\n    \n\n    \n\n        \ntrue\n\n        \nBacktrack\n\n    \n\n\n\n\nReserved lexical keyword table\n\n\n\n    \n\n        \nLexical Keyword\n\n    \n\n    \n\n        \n:any\n\n    \n\n    \n\n        \n$\n\n    \n\n\n\n\nTransition object table \n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \nfrom\n\n        \nState id, from source\n\n        \n0, 1, 2, ...\n\n        \nState id must exist and cannot correspond to a final state.\n\n        \nYes\n\n    \n\n    \n\n        \nto\n\n        \nState id, to destination\n\n        \n0, 1, 2, ...\n\n        \nState id must exist and cannot correspond to the initial state.\n\n        \nYes\n\n    \n\n    \n\n        \nchars\n\n        \nThe list of characters that will traverse this edge\n\n        \nArray of \nchar values\n\n        \nCheck table\n\n        \nYes, cannot be empty.\n\n    \n\n\n\n\nChar values table\n\n\n\n    \n\n        \nValue\n\n        \nDescription\n\n    \n\n    \n\n        \nCharacter (e.g. \n=\n)\n\n        \nA single character\n\n    \n\n    \n\n        \nEOF\n\n        \nEnd of file\n\n    \n\n    \n\n        \nNEW_LINE\n\n        \nNew line: \n\\n\n\n    \n\n    \n\n        \nRETURN\n\n        \nReturn: \n\\r\n\n    \n\n    \n\n        \nSPACE\n\n        \nSingle whitespace\n\n    \n\n    \n\n        \nTAB\n\n        \nSingle tab: \n\\t\n\n    \n\n    \n\n        \nLOWER_CASE_LETTER\n\n        \nA letter from a to z\n\n    \n\n    \n\n        \nUPPER_CASE_LETTER\n\n        \nA letter from A to Z\n\n    \n\n    \n\n        \nPOSITIVE\n\n        \nA positive digit from 1 to 9\n\n    \n\n    \n\n        \nOTHER\n\n        \nAny other character. Every non-final state must have a transition on \nOTHER\n\n    \n\n\n\n\nII - Lexical configuration\n\n\nLexical configuration allow manipulating and tagging generated tokens.\n\n\nJSON structure\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n    \n\n    \n\n        \nnewline\n\n        \nLine separator\n\n        \nCR\n\n        \n\\r\n\n    \n\n    \n\n        \nLF\n\n        \n\\n\n\n    \n\n    \n\n        \nCRLF\n\n        \n\\r\\n\n\n    \n\n    \n\n        \nignore\n\n        \nList of lexical tokens to be ignored (e.g. code comments)\n\n        \nIgnore object\n\n        \nCheck table\n\n    \n\n    \n\n        \nerror\n\n        \nList of lexical tokens resulting in lexical error\n\n        \nError object\n\n        \nCheck table\n\n    \n\n    \n\n        \nreserved\n\n        \nManipulate token name once created. This is useful when the user input has a reserved\n        keyword and the state machine marked it as a more general name.\n\n        \nReserved object\n\n        \nCheck table\n\n    \n\n\n\n\nIgnore object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nprefix\n\n        \nToken name prefix\n\n        \nstring\n\n    \n\n    \n\n        \nsuffix\n\n        \nToken name suffix\n\n        \nstring\n\n    \n\n    \n\n        \ninclude\n\n        \nList of all the token names not covered by the \nprefix\n or \nsuffix\n\n        \nArray of strings\n\n    \n\n    \n\n        \nexclude\n\n        \nList of all the token names covered by the \nprefix\n or \nsuffix\n but should\n        not be considered.\n\n        \nArray of strings\n\n    \n\n\n\n\nError object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nprefix\n\n        \nToken name prefix\n\n        \nstring\n\n    \n\n    \n\n        \nsuffix\n\n        \nToken name suffix\n\n        \nstring\n\n    \n\n    \n\n        \ninclude\n\n        \nList of all the token names not covered by the \nprefix\n or \nsuffix\n\n        \nArray of strings\n\n    \n\n    \n\n        \nexclude\n\n        \nList of all the token names covered by the \nprefix\n or \nsuffix\n but should\n        not be considered.\n\n        \nArray of strings\n\n    \n\n\n\n\nReserved object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nToken name (e.g. \nT_IDENTIFIER\n)\n\n        \nThe original token name assigned to the lexical token\n\n        \nReserved token object\n\n    \n\n    \n\n        \nNote: The above row can be applied several times in this object\n\n    \n\n\n\n\nReserved token object table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n    \n\n    \n\n        \nstring (e.g. \nif\n)\n\n        \nInput match\n\n        \nstring (e.g. \nT_IF\n)\n\n        \nNew token name\n\n    \n\n    \n\n        \nNote: The above row can be applied several times in this object\n\n    \n\n\n\n\nIII - Lexical error messages\n\n\nError messages reported by error tokens can be customized to provide meaningful information for the user.\n\n\nJSON structure\n\n\nGlobal key table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n    \n\n    \n\n        \ndefault_message\n\n        \nA default message, used if no specific message is defined for the error token.\n\n        \nstring\n\n        \nGeneral error message. The string can contain \noptional \n        placeholders\n.\n\n    \n\n        \nerror_messages\n\n        \nSpecific message for an error token\n\n        \nObject of \nerror message\n\n        \nCheck table\n\n    \n\n\n\n\nError message object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nToken name (e.g. \nT_INVALID_CHAR\n)\n\n        \nPrint error message when the error token is generated.\n\n        \nSpecific error message. The string can contain \noptional\n        placeholders\n\n    \n\n\n\n\nPlaceholders table\n\n\n\n    \n\n        \nPlaceholder\n\n        \nDescription\n\n    \n\n    \n\n        \n${value}\n\n        \nInput value of the lexical token.\n\n    \n\n    \n\n        \n${column}\n\n        \nHorizontal position of the lexical token.\n\n    \n\n    \n\n        \n${line}\n\n        \nLine number where the lexical token is found.\n\n    \n\n    \n\n        \n${filename}\n\n        \nInput file name.",
            "title": "Lexical analysis"
        },
        {
            "location": "/lexical/#lexical-analysis",
            "text": "",
            "title": "Lexical analysis"
        },
        {
            "location": "/lexical/#description",
            "text": "The lexical analysis is the first phase in compiler design where the user input is scanned and converted \ninto a sequence of tokens. The generated lexical tokens are then provided as input to the syntax analyzer.",
            "title": "Description"
        },
        {
            "location": "/lexical/#i-state-machine",
            "text": "A state machine is a graph composed of vertices connected by edges. The graph has a single starting vertex\nand one or more middle or final tokens. Landing on a final vertex means that a new token is created.\nEdges allow input characters to traverse the graph by assigning a letter label to each edge.",
            "title": "I - State machine"
        },
        {
            "location": "/lexical/#json-structure",
            "text": "Global keys table  \n     \n         Key \n         Description \n         Value \n     \n     \n         states \n         List of states/vertices of the state machine \n         Array of  state objects \n     \n     \n         transitions \n         List of transitions/edges of the state machine \n         Array of  transition objects \n       State object table  \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         type \n         Type of the state \n         Initial \n         Initial state. Exactly one state must be marked as initial \n         Yes \n     \n     \n         NORMAL \n         Normal state. \n     \n     \n         FINAL \n         Final state. \n     \n     \n         id \n         Unique id for each state \n         0, 1, 2, ... \n         Counting starts from 0 and should be consecutive \n         Yes \n     \n     \n         token \n         Name of the token created when landing on a final state \n         string (e.g.  T_SEMICOLON ) \n         Cannot be a  reserved lexical keyword \n         Only for final states \n     \n     \n         backtrack \n         Backtrack one character in the user input. This is required when the only possible \n        way to know that the token value has ended is by reading a character that is not part of the token \n        value. \n         false \n         Do not backtrack \n         Only for final states \n     \n     \n         true \n         Backtrack \n       Reserved lexical keyword table  \n     \n         Lexical Keyword \n     \n     \n         :any \n     \n     \n         $ \n       Transition object table   \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         from \n         State id, from source \n         0, 1, 2, ... \n         State id must exist and cannot correspond to a final state. \n         Yes \n     \n     \n         to \n         State id, to destination \n         0, 1, 2, ... \n         State id must exist and cannot correspond to the initial state. \n         Yes \n     \n     \n         chars \n         The list of characters that will traverse this edge \n         Array of  char values \n         Check table \n         Yes, cannot be empty. \n       Char values table  \n     \n         Value \n         Description \n     \n     \n         Character (e.g.  = ) \n         A single character \n     \n     \n         EOF \n         End of file \n     \n     \n         NEW_LINE \n         New line:  \\n \n     \n     \n         RETURN \n         Return:  \\r \n     \n     \n         SPACE \n         Single whitespace \n     \n     \n         TAB \n         Single tab:  \\t \n     \n     \n         LOWER_CASE_LETTER \n         A letter from a to z \n     \n     \n         UPPER_CASE_LETTER \n         A letter from A to Z \n     \n     \n         POSITIVE \n         A positive digit from 1 to 9 \n     \n     \n         OTHER \n         Any other character. Every non-final state must have a transition on  OTHER",
            "title": "JSON structure"
        },
        {
            "location": "/lexical/#ii-lexical-configuration",
            "text": "Lexical configuration allow manipulating and tagging generated tokens.",
            "title": "II - Lexical configuration"
        },
        {
            "location": "/lexical/#json-structure_1",
            "text": "Global keys table  \n     \n         Key \n         Key description \n         Value \n         Value description \n     \n     \n         newline \n         Line separator \n         CR \n         \\r \n     \n     \n         LF \n         \\n \n     \n     \n         CRLF \n         \\r\\n \n     \n     \n         ignore \n         List of lexical tokens to be ignored (e.g. code comments) \n         Ignore object \n         Check table \n     \n     \n         error \n         List of lexical tokens resulting in lexical error \n         Error object \n         Check table \n     \n     \n         reserved \n         Manipulate token name once created. This is useful when the user input has a reserved\n        keyword and the state machine marked it as a more general name. \n         Reserved object \n         Check table \n       Ignore object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         prefix \n         Token name prefix \n         string \n     \n     \n         suffix \n         Token name suffix \n         string \n     \n     \n         include \n         List of all the token names not covered by the  prefix  or  suffix \n         Array of strings \n     \n     \n         exclude \n         List of all the token names covered by the  prefix  or  suffix  but should\n        not be considered. \n         Array of strings \n       Error object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         prefix \n         Token name prefix \n         string \n     \n     \n         suffix \n         Token name suffix \n         string \n     \n     \n         include \n         List of all the token names not covered by the  prefix  or  suffix \n         Array of strings \n     \n     \n         exclude \n         List of all the token names covered by the  prefix  or  suffix  but should\n        not be considered. \n         Array of strings \n       Reserved object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         Token name (e.g.  T_IDENTIFIER ) \n         The original token name assigned to the lexical token \n         Reserved token object \n     \n     \n         Note: The above row can be applied several times in this object \n       Reserved token object table  \n     \n         Key \n         Key description \n         Value \n         Value description \n     \n     \n         string (e.g.  if ) \n         Input match \n         string (e.g.  T_IF ) \n         New token name \n     \n     \n         Note: The above row can be applied several times in this object",
            "title": "JSON structure"
        },
        {
            "location": "/lexical/#iii-lexical-error-messages",
            "text": "Error messages reported by error tokens can be customized to provide meaningful information for the user.",
            "title": "III - Lexical error messages"
        },
        {
            "location": "/lexical/#json-structure_2",
            "text": "Global key table  \n     \n         Key \n         Key description \n         Value \n         Value description \n     \n     \n         default_message \n         A default message, used if no specific message is defined for the error token. \n         string \n         General error message. The string can contain  optional \n        placeholders . \n     \n         error_messages \n         Specific message for an error token \n         Object of  error message \n         Check table \n       Error message object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         Token name (e.g.  T_INVALID_CHAR ) \n         Print error message when the error token is generated. \n         Specific error message. The string can contain  optional\n        placeholders \n       Placeholders table  \n     \n         Placeholder \n         Description \n     \n     \n         ${value} \n         Input value of the lexical token. \n     \n     \n         ${column} \n         Horizontal position of the lexical token. \n     \n     \n         ${line} \n         Line number where the lexical token is found. \n     \n     \n         ${filename} \n         Input file name.",
            "title": "JSON structure"
        },
        {
            "location": "/syntax/",
            "text": "",
            "title": "Syntax analysis"
        },
        {
            "location": "/semantic/",
            "text": "",
            "title": "Semantic analysis"
        },
        {
            "location": "/code/",
            "text": "",
            "title": "Code generation"
        },
        {
            "location": "/example/",
            "text": "",
            "title": "Calculator example"
        }
    ]
}