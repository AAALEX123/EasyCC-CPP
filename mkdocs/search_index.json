{
    "docs": [
        {
            "location": "/",
            "text": "EasyCC C++ \n\n\nGithub\n\n\nLink: \nhttps://github.com/amirbawab/EasyCC-CPP\n\n\nAbout\n\n\nEasyCC C++ (Easy Compiler Compiler written in C++) is a library allowing users to easily develop their own programming language. The project does not require wrting any line of code for the lexical and syntax analysis phases. The configurations of the latters are provided as JSON files to the library. Adding the logic for a programming language is done by simply registering semantic action handlers in order to gradually build the structure of the input and eventually generating output code.\n\n\nUsage\n\n\nNote: The library depends on Boost 1.63.0, make sure it is installed before compiling the project (Instructions can be found in \n.travis.yml\n file).\n\n\nCMakeLists.txt\n\n\ncmake_minimum_required(VERSION 3.5)\nproject(myProject)\nset(MYPROJECT_DEV_EXEC \"myproject_dev\")\nset(MYPROJECT_PRO_EXEC \"myproject_pro\")\n\nadd_subdirectory(EasyCC-CPP)\nadd_compile_options(-std=c++11)\n\n# Configure directory of output file\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# Include easycc header files\ninclude_directories(EasyCC-CPP/include)\n\n# Add the executables\nadd_executable(${MYPROJECT_DEV_EXEC} maindev.cpp)\nadd_executable(${MYPROJECT_PRO_EXEC} mainpro.cpp)\n\n# Link library to the executable\ntarget_link_libraries(${MYPROJECT_DEV_EXEC} easyccdev)\ntarget_link_libraries(${MYPROJECT_PRO_EXEC} easyccpro)\n\n\n\n\nFor a full \nCMakeLists.txt\n example, check \nBashClass\n which uses EasyCC C++ library\n\n\nDifference between \neasyccdev\n and \neasyccpro\n libraries\n\n\nBoth libraries use the same Lexical and Syntax algorithms, and switching from one library to another requires minor changes.\n\n\n\n\neasyccdev\n (EasyCC development mode) takes the JSON files as arguments in the final executable. This is useful during the development phase because the program does not need to be recompiled to apply changes in the JSON files.\n\n\neasyccpro\n (EasyCC production mode) takes the JSON files as arguments to the \ncmake\n program. The compile process for your program will be composed of two steps. First is embedding the JSON files into the executable, and  second is compiling your program with the generated files.\n\n\n\n\nContribution\n\n\n\n\nFeel free to contribute",
            "title": "Home"
        },
        {
            "location": "/#easycc-c",
            "text": "",
            "title": "EasyCC C++"
        },
        {
            "location": "/#github",
            "text": "Link:  https://github.com/amirbawab/EasyCC-CPP",
            "title": "Github"
        },
        {
            "location": "/#about",
            "text": "EasyCC C++ (Easy Compiler Compiler written in C++) is a library allowing users to easily develop their own programming language. The project does not require wrting any line of code for the lexical and syntax analysis phases. The configurations of the latters are provided as JSON files to the library. Adding the logic for a programming language is done by simply registering semantic action handlers in order to gradually build the structure of the input and eventually generating output code.",
            "title": "About"
        },
        {
            "location": "/#usage",
            "text": "Note: The library depends on Boost 1.63.0, make sure it is installed before compiling the project (Instructions can be found in  .travis.yml  file).",
            "title": "Usage"
        },
        {
            "location": "/#cmakeliststxt",
            "text": "cmake_minimum_required(VERSION 3.5)\nproject(myProject)\nset(MYPROJECT_DEV_EXEC \"myproject_dev\")\nset(MYPROJECT_PRO_EXEC \"myproject_pro\")\n\nadd_subdirectory(EasyCC-CPP)\nadd_compile_options(-std=c++11)\n\n# Configure directory of output file\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# Include easycc header files\ninclude_directories(EasyCC-CPP/include)\n\n# Add the executables\nadd_executable(${MYPROJECT_DEV_EXEC} maindev.cpp)\nadd_executable(${MYPROJECT_PRO_EXEC} mainpro.cpp)\n\n# Link library to the executable\ntarget_link_libraries(${MYPROJECT_DEV_EXEC} easyccdev)\ntarget_link_libraries(${MYPROJECT_PRO_EXEC} easyccpro)  For a full  CMakeLists.txt  example, check  BashClass  which uses EasyCC C++ library",
            "title": "CMakeLists.txt"
        },
        {
            "location": "/#difference-between-easyccdev-and-easyccpro-libraries",
            "text": "Both libraries use the same Lexical and Syntax algorithms, and switching from one library to another requires minor changes.   easyccdev  (EasyCC development mode) takes the JSON files as arguments in the final executable. This is useful during the development phase because the program does not need to be recompiled to apply changes in the JSON files.  easyccpro  (EasyCC production mode) takes the JSON files as arguments to the  cmake  program. The compile process for your program will be composed of two steps. First is embedding the JSON files into the executable, and  second is compiling your program with the generated files.",
            "title": "Difference between easyccdev and easyccpro libraries"
        },
        {
            "location": "/#contribution",
            "text": "Feel free to contribute",
            "title": "Contribution"
        },
        {
            "location": "/lexical/",
            "text": "Lexical analysis\n\n\nDescription\n\n\nThe lexical analysis is the first phase in compiler design where the user input is scanned and converted \ninto a sequence of tokens. The generated lexical tokens are then provided as input to the syntax analyzer.\n\n\nI - State machine\n\n\nA state machine is a graph composed of vertices connected by edges. The graph has a single starting vertex\nand one or more middle or final tokens. Landing on a final vertex means that a new token is created.\nEdges allow input characters to traverse the graph by assigning a letter label to each edge.  \n\n\nJSON structure\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n        \nRequired\n\n    \n\n    \n\n        \nstates\n\n        \nList of states/vertices of the state machine\n\n        \nArray of \nstate objects\n\n        \nYes\n\n    \n\n    \n\n        \ntransitions\n\n        \nList of transitions/edges of the state machine\n\n        \nArray of \ntransition objects\n\n        \nYes\n\n    \n\n\n\n\nState object table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \ntype\n\n        \nType of the state\n\n        \nInitial\n\n        \nInitial state. Exactly one state must be marked as initial\n\n        \nYes\n\n    \n\n    \n\n        \nNORMAL\n\n        \nNormal state.\n\n    \n\n    \n\n        \nFINAL\n\n        \nFinal state.\n\n    \n\n    \n\n        \nid\n\n        \nUnique id for each state\n\n        \n0, 1, 2, ...\n\n        \nCounting starts from 0 and should be consecutive\n\n        \nYes\n\n    \n\n    \n\n        \ntoken\n\n        \nName of the token created when landing on a final state\n\n        \nstring (e.g. \nT_SEMICOLON\n)\n\n        \nCannot be a \nreserved syntax keyword\n\n        \nOnly for final states\n\n    \n\n    \n\n        \nbacktrack\n\n        \nBacktrack one character in the user input. This is required when the only possible \n        way to know that the token value has ended is by reading a character that is not part of the token \n        value.\n\n        \nfalse\n\n        \nDo not backtrack\n\n        \nOnly for final states\n\n    \n\n    \n\n        \ntrue\n\n        \nBacktrack\n\n    \n\n\n\n\nTransition object table \n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \nfrom\n\n        \nState id, from source\n\n        \n0, 1, 2, ...\n\n        \nState id must exist and cannot correspond to a final state.\n\n        \nYes\n\n    \n\n    \n\n        \nto\n\n        \nState id, to destination\n\n        \n0, 1, 2, ...\n\n        \nState id must exist and cannot correspond to the initial state.\n\n        \nYes\n\n    \n\n    \n\n        \nchars\n\n        \nThe list of characters that will traverse this edge\n\n        \nArray of \nchar values\n\n        \nCheck table\n\n        \nYes, cannot be empty.\n\n    \n\n\n\n\nChar values table\n\n\n\n    \n\n        \nValue\n\n        \nDescription\n\n    \n\n    \n\n        \nCharacter (e.g. \n=\n)\n\n        \nA single character\n\n    \n\n    \n\n        \nEOF\n\n        \nEnd of file\n\n    \n\n    \n\n        \nNEW_LINE\n\n        \nNew line: \n\\n\n\n    \n\n    \n\n        \nRETURN\n\n        \nReturn: \n\\r\n\n    \n\n    \n\n        \nSPACE\n\n        \nSingle whitespace\n\n    \n\n    \n\n        \nTAB\n\n        \nSingle tab: \n\\t\n\n    \n\n    \n\n        \nLOWER_CASE_LETTER\n\n        \nA letter from a to z\n\n    \n\n    \n\n        \nUPPER_CASE_LETTER\n\n        \nA letter from A to Z\n\n    \n\n    \n\n        \nPOSITIVE\n\n        \nA positive digit from 1 to 9\n\n    \n\n    \n\n        \nOTHER\n\n        \nAny other character. Every non-final state must have a transition on \nOTHER\n\n    \n\n\n\n\nII - Lexical configuration\n\n\nLexical configuration allow manipulating and tagging generated tokens.\n\n\nJSON structure\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \nnewline\n\n        \nLine separator\n\n        \nCR\n\n        \n\\r\n\n        \nYes\n\n    \n\n    \n\n        \nLF\n\n        \n\\n\n\n    \n\n    \n\n        \nCRLF\n\n        \n\\r\\n\n\n    \n\n    \n\n        \nignore\n\n        \nList of lexical tokens to be ignored (e.g. code comments)\n\n        \nIgnore object\n\n        \nCheck table\n\n        \nYes\n\n    \n\n    \n\n        \nerror\n\n        \nList of lexical tokens resulting in lexical error\n\n        \nError object\n\n        \nCheck table\n\n        \nYes\n\n    \n\n    \n\n        \nreserved\n\n        \nManipulate token name once created. This is useful when the user input has a reserved\n        keyword and the state machine marked it as a more general name.\n\n        \nReserved object\n\n        \nCheck table\n\n        \nYes\n\n    \n\n\n\n\nIgnore object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nprefix\n\n        \nToken name prefix\n\n        \nstring\n\n    \n\n    \n\n        \nsuffix\n\n        \nToken name suffix\n\n        \nstring\n\n    \n\n    \n\n        \ninclude\n\n        \nList of all the token names not covered by the \nprefix\n or \nsuffix\n\n        \nArray of strings\n\n    \n\n    \n\n        \nexclude\n\n        \nList of all the token names covered by the \nprefix\n or \nsuffix\n but should\n        not be considered.\n\n        \nArray of strings\n\n    \n\n\n\n\nError object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nprefix\n\n        \nToken name prefix\n\n        \nstring\n\n    \n\n    \n\n        \nsuffix\n\n        \nToken name suffix\n\n        \nstring\n\n    \n\n    \n\n        \ninclude\n\n        \nList of all the token names not covered by the \nprefix\n or \nsuffix\n\n        \nArray of strings\n\n    \n\n    \n\n        \nexclude\n\n        \nList of all the token names covered by the \nprefix\n or \nsuffix\n but should\n        not be considered.\n\n        \nArray of strings\n\n    \n\n\n\n\nReserved object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nToken name (e.g. \nT_IDENTIFIER\n)\n\n        \nThe original token name assigned to the lexical token\n\n        \nReserved token object\n\n    \n\n    \n\n        \nNote: The above row can be applied several times in this object\n\n    \n\n\n\n\nReserved token object table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n    \n\n    \n\n        \nstring (e.g. \nif\n)\n\n        \nInput match\n\n        \nstring (e.g. \nT_IF\n)\n\n        \nNew token name\n\n    \n\n    \n\n        \nNote: The above row can be applied several times in this object\n\n    \n\n\n\n\nIII - Lexical error messages\n\n\nError messages reported by error tokens can be customized to provide meaningful information for the user.\n\n\nJSON structure\n\n\nGlobal key table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \ndefault_message\n\n        \nA default message, used if no specific message is defined for the error token.\n\n        \nstring\n\n        \nGeneral error message. The string can contain \noptional \n        placeholders\n.\n\n        \nYes\n\n    \n\n        \nerror_messages\n\n        \nSpecific message for an error token\n\n        \nObject of \nerror message\n\n        \nCheck table\n\n        \nYes\n\n    \n\n\n\n\nError message object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nToken name (e.g. \nT_INVALID_CHAR\n)\n\n        \nPrint error message when the error token is generated.\n\n        \nSpecific error message. The string can contain \noptional\n        placeholders\n\n    \n\n\n\n\nPlaceholders table\n\n\n\n    \n\n        \nPlaceholder\n\n        \nDescription\n\n    \n\n    \n\n        \n${value}\n\n        \nInput value of the lexical token.\n\n    \n\n    \n\n        \n${column}\n\n        \nHorizontal position of the lexical token.\n\n    \n\n    \n\n        \n${line}\n\n        \nLine number where the lexical token is found.\n\n    \n\n    \n\n        \n${filename}\n\n        \nInput file name.",
            "title": "Lexical analysis"
        },
        {
            "location": "/lexical/#lexical-analysis",
            "text": "",
            "title": "Lexical analysis"
        },
        {
            "location": "/lexical/#description",
            "text": "The lexical analysis is the first phase in compiler design where the user input is scanned and converted \ninto a sequence of tokens. The generated lexical tokens are then provided as input to the syntax analyzer.",
            "title": "Description"
        },
        {
            "location": "/lexical/#i-state-machine",
            "text": "A state machine is a graph composed of vertices connected by edges. The graph has a single starting vertex\nand one or more middle or final tokens. Landing on a final vertex means that a new token is created.\nEdges allow input characters to traverse the graph by assigning a letter label to each edge.",
            "title": "I - State machine"
        },
        {
            "location": "/lexical/#json-structure",
            "text": "Global keys table  \n     \n         Key \n         Description \n         Value \n         Required \n     \n     \n         states \n         List of states/vertices of the state machine \n         Array of  state objects \n         Yes \n     \n     \n         transitions \n         List of transitions/edges of the state machine \n         Array of  transition objects \n         Yes \n       State object table  \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         type \n         Type of the state \n         Initial \n         Initial state. Exactly one state must be marked as initial \n         Yes \n     \n     \n         NORMAL \n         Normal state. \n     \n     \n         FINAL \n         Final state. \n     \n     \n         id \n         Unique id for each state \n         0, 1, 2, ... \n         Counting starts from 0 and should be consecutive \n         Yes \n     \n     \n         token \n         Name of the token created when landing on a final state \n         string (e.g.  T_SEMICOLON ) \n         Cannot be a  reserved syntax keyword \n         Only for final states \n     \n     \n         backtrack \n         Backtrack one character in the user input. This is required when the only possible \n        way to know that the token value has ended is by reading a character that is not part of the token \n        value. \n         false \n         Do not backtrack \n         Only for final states \n     \n     \n         true \n         Backtrack \n       Transition object table   \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         from \n         State id, from source \n         0, 1, 2, ... \n         State id must exist and cannot correspond to a final state. \n         Yes \n     \n     \n         to \n         State id, to destination \n         0, 1, 2, ... \n         State id must exist and cannot correspond to the initial state. \n         Yes \n     \n     \n         chars \n         The list of characters that will traverse this edge \n         Array of  char values \n         Check table \n         Yes, cannot be empty. \n       Char values table  \n     \n         Value \n         Description \n     \n     \n         Character (e.g.  = ) \n         A single character \n     \n     \n         EOF \n         End of file \n     \n     \n         NEW_LINE \n         New line:  \\n \n     \n     \n         RETURN \n         Return:  \\r \n     \n     \n         SPACE \n         Single whitespace \n     \n     \n         TAB \n         Single tab:  \\t \n     \n     \n         LOWER_CASE_LETTER \n         A letter from a to z \n     \n     \n         UPPER_CASE_LETTER \n         A letter from A to Z \n     \n     \n         POSITIVE \n         A positive digit from 1 to 9 \n     \n     \n         OTHER \n         Any other character. Every non-final state must have a transition on  OTHER",
            "title": "JSON structure"
        },
        {
            "location": "/lexical/#ii-lexical-configuration",
            "text": "Lexical configuration allow manipulating and tagging generated tokens.",
            "title": "II - Lexical configuration"
        },
        {
            "location": "/lexical/#json-structure_1",
            "text": "Global keys table  \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         newline \n         Line separator \n         CR \n         \\r \n         Yes \n     \n     \n         LF \n         \\n \n     \n     \n         CRLF \n         \\r\\n \n     \n     \n         ignore \n         List of lexical tokens to be ignored (e.g. code comments) \n         Ignore object \n         Check table \n         Yes \n     \n     \n         error \n         List of lexical tokens resulting in lexical error \n         Error object \n         Check table \n         Yes \n     \n     \n         reserved \n         Manipulate token name once created. This is useful when the user input has a reserved\n        keyword and the state machine marked it as a more general name. \n         Reserved object \n         Check table \n         Yes \n       Ignore object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         prefix \n         Token name prefix \n         string \n     \n     \n         suffix \n         Token name suffix \n         string \n     \n     \n         include \n         List of all the token names not covered by the  prefix  or  suffix \n         Array of strings \n     \n     \n         exclude \n         List of all the token names covered by the  prefix  or  suffix  but should\n        not be considered. \n         Array of strings \n       Error object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         prefix \n         Token name prefix \n         string \n     \n     \n         suffix \n         Token name suffix \n         string \n     \n     \n         include \n         List of all the token names not covered by the  prefix  or  suffix \n         Array of strings \n     \n     \n         exclude \n         List of all the token names covered by the  prefix  or  suffix  but should\n        not be considered. \n         Array of strings \n       Reserved object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         Token name (e.g.  T_IDENTIFIER ) \n         The original token name assigned to the lexical token \n         Reserved token object \n     \n     \n         Note: The above row can be applied several times in this object \n       Reserved token object table  \n     \n         Key \n         Key description \n         Value \n         Value description \n     \n     \n         string (e.g.  if ) \n         Input match \n         string (e.g.  T_IF ) \n         New token name \n     \n     \n         Note: The above row can be applied several times in this object",
            "title": "JSON structure"
        },
        {
            "location": "/lexical/#iii-lexical-error-messages",
            "text": "Error messages reported by error tokens can be customized to provide meaningful information for the user.",
            "title": "III - Lexical error messages"
        },
        {
            "location": "/lexical/#json-structure_2",
            "text": "Global key table  \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         default_message \n         A default message, used if no specific message is defined for the error token. \n         string \n         General error message. The string can contain  optional \n        placeholders . \n         Yes \n     \n         error_messages \n         Specific message for an error token \n         Object of  error message \n         Check table \n         Yes \n       Error message object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         Token name (e.g.  T_INVALID_CHAR ) \n         Print error message when the error token is generated. \n         Specific error message. The string can contain  optional\n        placeholders \n       Placeholders table  \n     \n         Placeholder \n         Description \n     \n     \n         ${value} \n         Input value of the lexical token. \n     \n     \n         ${column} \n         Horizontal position of the lexical token. \n     \n     \n         ${line} \n         Line number where the lexical token is found. \n     \n     \n         ${filename} \n         Input file name.",
            "title": "JSON structure"
        },
        {
            "location": "/syntax/",
            "text": "Syntax analysis\n\n\nDescription\n\n\nSyntax analysis is the second phase in compiler design where the lexical tokens generated by the lexical \nanalyzer are validated against a grammar defining the language syntax. \n\n\nI - Grammar\n\n\nA language syntax is determined by a set of productions forming a grammar. Constructed grammars must \nsatisfy the LL(1) (left to right, leftmost derivation, 1 lookahead) conditions.\n\n\nLL(1) Conditions\n\n\nA - No left recursion\n\n\nExample of a left recursion\n\n\nA -> A a | b\n\n\n\n\nSolution for a left recursion\n\n\nA -> b B\nB -> a B | \u03b5\n\n\n\n\nB - Intersection of First sets in same production must be empty\n\n\nExample of a non-empty intersection of First sets in a same production\n\n\nA -> B C | D E\nB -> F G\nD -> F H\n\n\n\n\nIn the above grammar, First(F) \u2208 First(B) and First(F) \u2208 First(D), therefore First(B) \u2229 First(D) \u2260 {}\n\n\nOne solution for this problem\n\n\nA -> F I\nI -> G C | H E\n\n\n\n\nC - Intersection of First and Follow sets of a non-terminal must be empty\n\n\nExample of a non-empty intersection of First and Follow sets of a non-terminal\n\n\nA -> B a\nB -> a | \u03b5\n\n\n\n\nIn the above grammar, First(B) \u2229 Follow(B) = {a}\n\n\nOne solution for this problem\n\n\nA -> a C\nC -> a | \u03b5\n\n\n\n\nJSON structure\n\n\nTerminals and Non-terminals\n\n\n\n\nNon-terminals must be composed of upper case letters and underscore only. (Cannot be part of\n\nReserved syntax keywords\n)\n\n\nTerminals must begin and end with a single quote. The text in between the single quotes defines the\nlexical token name (case sensitive) and should not contain spaces. (Cannot be part of\n\nReserved syntax keywords\n)\n\n\nEPSILON\n represents an epsilon production.\n\n\nWhitespaces between tokens are delimiters.\n\n\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n    \n\n    \n\n        \nnon-terminal (e.g. \nT_IF\n)\n\n        \nThe non-terminal that can be replaced by its value.\n\n        \nArray of non-terminals string (e.g. \n[\"NT_A NT_B NT_C\"]\n)\n\n    \n\n    \n\n        \nArray of a terminal string (e.g. \n[\"'if'\"]\n)\n\n    \n\n    \n\n        \nArray of an epsilon string (e.g. \n[\"EPSILON\"]\n)\n\n    \n\n    \n\n        \nArray of a mix strings (e.g. \n[\"NT_A NT_B NT_C\", \"'if'\", \"EPSILON\"]\n)\n\n    \n\n    \n\n        \nNote: The above row can be applied several times in this object\n\n    \n\n\n\n\nReserved syntax keyword table\n\n\n\n    \n\n        \nLexical Keyword\n\n    \n\n    \n\n        \n:any\n\n    \n\n    \n\n        \n$\n\n    \n\n\n\n\nII - Syntax error messages\n\n\nWhen the user input does not align with the language grammar, the syntax analyzer will try to recover\nfrom the panic mode and will report customized error messages describing each situation.\n\n\nJSON structure\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \ndefault_message\n\n        \nA default message, used if no specific message is defined for a particular situation.\n\n        \nstring\n\n        \nGeneral error message. The string can contain \noptional placeholders\n.\n\n        \nYes\n\n    \n\n    \n\n        \nerror_messages\n\n        \nSpecific message for a particular situation.\n\n        \nArray of \nerror message objects\n\n        \nCheck table\n\n        \nYes\n\n    \n\n\n\n\nError message object table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n    \n\n    \n\n        \nnon_terminal\n\n        \nNon-terminal expected by the syntax analyzer at a specific location in the input\n\n        \nstring\n\n        \nNon-terminal (e.g. \nT_VAR_NAME\n)\n\n    \n\n    \n\n        \n:any\n\n        \nAny non-terminal\n\n    \n\n    \n\n        \n$\n\n        \nEnd of grammar\n\n    \n\n    \n\n        \nterminal\n\n        \nActual terminal read by the syntax analyzer\n\n        \nstring\n\n        \nTerminal (e.g. \n'equal_sign'\n)\n\n    \n\n    \n\n        \n:any\n\n        \nAny terminal\n\n    \n\n    \n\n        \n$\n\n        \nEnd of file\n\n    \n\n    \n\n        \nmessage\n\n        \nError message\n\n        \nstring\n\n        \nMeaningful message on what was added or unexpected.\n(e.g. 'Missing variable name before the \n        assignment operator at line ${lexical.line}').\nThe string can contain \n        \noptional placeholders\n.\n\n    \n\n\n\n\nPlaceholders table\n\n\n\n    \n\n        \nPlaceholder\n\n        \nDescription\n\n    \n\n    \n\n        \n${lexical[.next|.previous]*.value}\n\n        \nDisplay the value of the token object\n\n    \n\n    \n\n        \n${lexical[.next|.previous]*.column}\n\n        \nDisplay the column number in the line starting from 1\n\n    \n\n    \n\n        \n${lexical[.next|.previous]*.line}\n\n        \nDisplay the line number in the text starting from 1\n\n    \n\n    \n\n        \n${filename}\n\n        \nInput file name.",
            "title": "Syntax analysis"
        },
        {
            "location": "/syntax/#syntax-analysis",
            "text": "",
            "title": "Syntax analysis"
        },
        {
            "location": "/syntax/#description",
            "text": "Syntax analysis is the second phase in compiler design where the lexical tokens generated by the lexical \nanalyzer are validated against a grammar defining the language syntax.",
            "title": "Description"
        },
        {
            "location": "/syntax/#i-grammar",
            "text": "A language syntax is determined by a set of productions forming a grammar. Constructed grammars must \nsatisfy the LL(1) (left to right, leftmost derivation, 1 lookahead) conditions.",
            "title": "I - Grammar"
        },
        {
            "location": "/syntax/#ll1-conditions",
            "text": "",
            "title": "LL(1) Conditions"
        },
        {
            "location": "/syntax/#a-no-left-recursion",
            "text": "Example of a left recursion  A -> A a | b  Solution for a left recursion  A -> b B\nB -> a B | \u03b5",
            "title": "A - No left recursion"
        },
        {
            "location": "/syntax/#b-intersection-of-first-sets-in-same-production-must-be-empty",
            "text": "Example of a non-empty intersection of First sets in a same production  A -> B C | D E\nB -> F G\nD -> F H  In the above grammar, First(F) \u2208 First(B) and First(F) \u2208 First(D), therefore First(B) \u2229 First(D) \u2260 {}  One solution for this problem  A -> F I\nI -> G C | H E",
            "title": "B - Intersection of First sets in same production must be empty"
        },
        {
            "location": "/syntax/#c-intersection-of-first-and-follow-sets-of-a-non-terminal-must-be-empty",
            "text": "Example of a non-empty intersection of First and Follow sets of a non-terminal  A -> B a\nB -> a | \u03b5  In the above grammar, First(B) \u2229 Follow(B) = {a}  One solution for this problem  A -> a C\nC -> a | \u03b5",
            "title": "C - Intersection of First and Follow sets of a non-terminal must be empty"
        },
        {
            "location": "/syntax/#json-structure",
            "text": "Terminals and Non-terminals   Non-terminals must be composed of upper case letters and underscore only. (Cannot be part of Reserved syntax keywords )  Terminals must begin and end with a single quote. The text in between the single quotes defines the\nlexical token name (case sensitive) and should not contain spaces. (Cannot be part of Reserved syntax keywords )  EPSILON  represents an epsilon production.  Whitespaces between tokens are delimiters.   Global keys table  \n     \n         Key \n         Key description \n         Value \n     \n     \n         non-terminal (e.g.  T_IF ) \n         The non-terminal that can be replaced by its value. \n         Array of non-terminals string (e.g.  [\"NT_A NT_B NT_C\"] ) \n     \n     \n         Array of a terminal string (e.g.  [\"'if'\"] ) \n     \n     \n         Array of an epsilon string (e.g.  [\"EPSILON\"] ) \n     \n     \n         Array of a mix strings (e.g.  [\"NT_A NT_B NT_C\", \"'if'\", \"EPSILON\"] ) \n     \n     \n         Note: The above row can be applied several times in this object \n       Reserved syntax keyword table  \n     \n         Lexical Keyword \n     \n     \n         :any \n     \n     \n         $",
            "title": "JSON structure"
        },
        {
            "location": "/syntax/#ii-syntax-error-messages",
            "text": "When the user input does not align with the language grammar, the syntax analyzer will try to recover\nfrom the panic mode and will report customized error messages describing each situation.",
            "title": "II - Syntax error messages"
        },
        {
            "location": "/syntax/#json-structure_1",
            "text": "Global keys table  \n     \n         Key \n         Description \n         Value \n         Value description \n         Required \n     \n     \n         default_message \n         A default message, used if no specific message is defined for a particular situation. \n         string \n         General error message. The string can contain  optional placeholders . \n         Yes \n     \n     \n         error_messages \n         Specific message for a particular situation. \n         Array of  error message objects \n         Check table \n         Yes \n       Error message object table  \n     \n         Key \n         Key description \n         Value \n         Value description \n     \n     \n         non_terminal \n         Non-terminal expected by the syntax analyzer at a specific location in the input \n         string \n         Non-terminal (e.g.  T_VAR_NAME ) \n     \n     \n         :any \n         Any non-terminal \n     \n     \n         $ \n         End of grammar \n     \n     \n         terminal \n         Actual terminal read by the syntax analyzer \n         string \n         Terminal (e.g.  'equal_sign' ) \n     \n     \n         :any \n         Any terminal \n     \n     \n         $ \n         End of file \n     \n     \n         message \n         Error message \n         string \n         Meaningful message on what was added or unexpected. (e.g. 'Missing variable name before the \n        assignment operator at line ${lexical.line}'). The string can contain \n         optional placeholders . \n       Placeholders table  \n     \n         Placeholder \n         Description \n     \n     \n         ${lexical[.next|.previous]*.value} \n         Display the value of the token object \n     \n     \n         ${lexical[.next|.previous]*.column} \n         Display the column number in the line starting from 1 \n     \n     \n         ${lexical[.next|.previous]*.line} \n         Display the line number in the text starting from 1 \n     \n     \n         ${filename} \n         Input file name.",
            "title": "JSON structure"
        },
        {
            "location": "/semantic/",
            "text": "",
            "title": "Semantic analysis"
        },
        {
            "location": "/code/",
            "text": "",
            "title": "Code generation"
        },
        {
            "location": "/example/",
            "text": "",
            "title": "Calculator example"
        }
    ]
}