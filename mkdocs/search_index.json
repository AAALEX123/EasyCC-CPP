{
    "docs": [
        {
            "location": "/",
            "text": "Version\n: 1.2.0\n\n\nGithub\n\n\nLink: \nRelease 1.2.0\n\n\nAbout\n\n\nEasyCC C++ (Easy Compiler Compiler written in C++) is a library allowing users to easily develop their own programming language. The project does not require wrting any line of code for the lexical and syntax analysis phases. The configurations of the latters are provided as JSON files to the library. Adding the logic for a programming language is done by simply registering semantic action handlers in order to gradually build the structure of the input and eventually generating output code.\n\n\nUsage\n\n\nNote: The library depends on Boost 1.63.0, make sure it is installed before compiling the project (Instructions can be found in \n.travis.yml\n file).\n\n\nCMakeLists.txt\n\n\ncmake_minimum_required(VERSION 3.5)\nproject(myProject)\nset(MYPROJECT_DEV_EXEC \"myproject_dev\")\nset(MYPROJECT_PRO_EXEC \"myproject_pro\")\n\nadd_subdirectory(EasyCC-CPP)\nadd_compile_options(-std=c++11)\n\n# Configure directory of output file\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# Include easycc header files\ninclude_directories(EasyCC-CPP/include)\n\n# Add the executables\nadd_executable(${MYPROJECT_DEV_EXEC} maindev.cpp)\nadd_executable(${MYPROJECT_PRO_EXEC} mainpro.cpp)\n\n# Link library to the executable\ntarget_link_libraries(${MYPROJECT_DEV_EXEC} easyccdev)\ntarget_link_libraries(${MYPROJECT_PRO_EXEC} easyccpro)\n\n\n\n\nFor a full \nCMakeLists.txt\n example, check \nBashClass\n which uses EasyCC C++ library\n\n\nDifference between \neasyccdev\n and \neasyccpro\n libraries\n\n\nBoth libraries use the same Lexical and Syntax algorithms, and switching from one library to another requires minor changes.\n\n\n\n\neasyccdev\n (EasyCC development mode) takes the JSON files as arguments in the final executable. This is useful during the development phase because the program does not need to be recompiled to apply changes in the JSON files.\n\n\neasyccpro\n (EasyCC production mode) takes the JSON files as arguments to the \ncmake\n program. The compile process for your program will be composed of two steps. First is embedding the JSON files into the executable, and  second is compiling your program with the generated files.\n\n\n\n\nContribution\n\n\n\n\nFeel free to contribute",
            "title": "Home"
        },
        {
            "location": "/#github",
            "text": "Link:  Release 1.2.0",
            "title": "Github"
        },
        {
            "location": "/#about",
            "text": "EasyCC C++ (Easy Compiler Compiler written in C++) is a library allowing users to easily develop their own programming language. The project does not require wrting any line of code for the lexical and syntax analysis phases. The configurations of the latters are provided as JSON files to the library. Adding the logic for a programming language is done by simply registering semantic action handlers in order to gradually build the structure of the input and eventually generating output code.",
            "title": "About"
        },
        {
            "location": "/#usage",
            "text": "Note: The library depends on Boost 1.63.0, make sure it is installed before compiling the project (Instructions can be found in  .travis.yml  file).",
            "title": "Usage"
        },
        {
            "location": "/#cmakeliststxt",
            "text": "cmake_minimum_required(VERSION 3.5)\nproject(myProject)\nset(MYPROJECT_DEV_EXEC \"myproject_dev\")\nset(MYPROJECT_PRO_EXEC \"myproject_pro\")\n\nadd_subdirectory(EasyCC-CPP)\nadd_compile_options(-std=c++11)\n\n# Configure directory of output file\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# Include easycc header files\ninclude_directories(EasyCC-CPP/include)\n\n# Add the executables\nadd_executable(${MYPROJECT_DEV_EXEC} maindev.cpp)\nadd_executable(${MYPROJECT_PRO_EXEC} mainpro.cpp)\n\n# Link library to the executable\ntarget_link_libraries(${MYPROJECT_DEV_EXEC} easyccdev)\ntarget_link_libraries(${MYPROJECT_PRO_EXEC} easyccpro)  For a full  CMakeLists.txt  example, check  BashClass  which uses EasyCC C++ library",
            "title": "CMakeLists.txt"
        },
        {
            "location": "/#difference-between-easyccdev-and-easyccpro-libraries",
            "text": "Both libraries use the same Lexical and Syntax algorithms, and switching from one library to another requires minor changes.   easyccdev  (EasyCC development mode) takes the JSON files as arguments in the final executable. This is useful during the development phase because the program does not need to be recompiled to apply changes in the JSON files.  easyccpro  (EasyCC production mode) takes the JSON files as arguments to the  cmake  program. The compile process for your program will be composed of two steps. First is embedding the JSON files into the executable, and  second is compiling your program with the generated files.",
            "title": "Difference between easyccdev and easyccpro libraries"
        },
        {
            "location": "/#contribution",
            "text": "Feel free to contribute",
            "title": "Contribution"
        },
        {
            "location": "/lexical/",
            "text": "Lexical analysis\n\n\nDescription\n\n\nThe lexical analysis is the first phase in compiler design where the user input is scanned and converted \ninto a sequence of tokens. The generated lexical tokens are then provided as input to the syntax analyzer.\n\n\nI - State machine\n\n\nA state machine is a graph composed of vertices connected by edges. The graph has a single starting vertex\nand one or more middle or final tokens. Landing on a final vertex means that a new token is created.\nEdges allow input characters to traverse the graph by assigning a letter label to each edge.  \n\n\nJSON structure\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n        \nRequired\n\n    \n\n    \n\n        \nstates\n\n        \nList of states/vertices of the state machine\n\n        \nArray of \nstate objects\n\n        \nYes\n\n    \n\n    \n\n        \ntransitions\n\n        \nList of transitions/edges of the state machine\n\n        \nArray of \ntransition objects\n\n        \nYes\n\n    \n\n\n\n\nState object table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \ntype\n\n        \nType of the state\n\n        \nInitial\n\n        \nInitial state. Exactly one state must be marked as initial\n\n        \nYes\n\n    \n\n    \n\n        \nNORMAL\n\n        \nNormal state.\n\n    \n\n    \n\n        \nFINAL\n\n        \nFinal state.\n\n    \n\n    \n\n        \nid\n\n        \nUnique id for each state\n\n        \n0, 1, 2, ...\n\n        \nCounting starts from 0 and should be consecutive\n\n        \nYes\n\n    \n\n    \n\n        \ntoken\n\n        \nName of the token created when landing on a final state\n\n        \nstring (e.g. \nT_SEMICOLON\n)\n\n        \nCannot be a \nreserved syntax keyword\n\n        \nOnly for final states\n\n    \n\n    \n\n        \nbacktrack\n\n        \nBacktrack one character in the user input. This is required when the only possible \n        way to know that the token value has ended is by reading a character that is not part of the token \n        value.\n\n        \nfalse\n\n        \nDo not backtrack\n\n        \nOnly for final states\n\n    \n\n    \n\n        \ntrue\n\n        \nBacktrack\n\n    \n\n\n\n\nTransition object table \n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \nfrom\n\n        \nState id, from source\n\n        \n0, 1, 2, ...\n\n        \nState id must exist and cannot correspond to a final state.\n\n        \nYes\n\n    \n\n    \n\n        \nto\n\n        \nState id, to destination\n\n        \n0, 1, 2, ...\n\n        \nState id must exist and cannot correspond to the initial state.\n\n        \nYes\n\n    \n\n    \n\n        \nchars\n\n        \nThe list of characters that will traverse this edge\n\n        \nArray of \nchar values\n\n        \nCheck table\n\n        \nYes, cannot be empty.\n\n    \n\n\n\n\nChar values table\n\n\n\n    \n\n        \nValue\n\n        \nDescription\n\n    \n\n    \n\n        \nCharacter (e.g. \n=\n)\n\n        \nA single character\n\n    \n\n    \n\n        \nEOF\n\n        \nEnd of file\n\n    \n\n    \n\n        \nNEW_LINE\n\n        \nNew line: \n\\n\n\n    \n\n    \n\n        \nRETURN\n\n        \nReturn: \n\\r\n\n    \n\n    \n\n        \nSPACE\n\n        \nSingle whitespace\n\n    \n\n    \n\n        \nTAB\n\n        \nSingle tab: \n\\t\n\n    \n\n    \n\n        \nLOWER_CASE_LETTER\n\n        \nA letter from a to z\n\n    \n\n    \n\n        \nUPPER_CASE_LETTER\n\n        \nA letter from A to Z\n\n    \n\n    \n\n        \nPOSITIVE\n\n        \nA positive digit from 1 to 9\n\n    \n\n    \n\n        \nOTHER\n\n        \nAny other character. Every non-final state must have a transition on \nOTHER\n\n    \n\n\n\n\nGUI to JSON\n\n\nIntroduction\n\n\nA state machine can get large and it will become hard to keep track of states and transitions. To reduce the\ncomplexity of building state machines, use the \ngraph.html\n tool located under \ntools/gui/\n in order to\nbuild the machine using a graphical user interface and then export it to JSON. \n\n\nNote: The tool is written in TypeScript and needs to be compiled before using it.\n\n\nCompile tool\n\n\ncd tools/gui/ts/\ntsc @compile\n\n\n\n\nII - Lexical configuration\n\n\nLexical configuration allow manipulating and tagging generated tokens.\n\n\nJSON structure\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \nnewline\n\n        \nLine separator\n\n        \nCR\n\n        \n\\r\n\n        \nYes\n\n    \n\n    \n\n        \nLF\n\n        \n\\n\n\n    \n\n    \n\n        \nCRLF\n\n        \n\\r\\n\n\n    \n\n    \n\n        \nignore\n\n        \nList of lexical tokens to be ignored (e.g. code comments)\n\n        \nIgnore object\n\n        \nCheck table\n\n        \nYes\n\n    \n\n    \n\n        \nerror\n\n        \nList of lexical tokens resulting in lexical error\n\n        \nError object\n\n        \nCheck table\n\n        \nYes\n\n    \n\n    \n\n        \nreserved\n\n        \nManipulate token name once created. This is useful when the user input has a reserved\n        keyword and the state machine marked it as a more general name.\n\n        \nReserved object\n\n        \nCheck table\n\n        \nYes\n\n    \n\n\n\n\nIgnore object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nprefix\n\n        \nToken name prefix\n\n        \nstring\n\n    \n\n    \n\n        \nsuffix\n\n        \nToken name suffix\n\n        \nstring\n\n    \n\n    \n\n        \ninclude\n\n        \nList of all the token names not covered by the \nprefix\n or \nsuffix\n\n        \nArray of strings\n\n    \n\n    \n\n        \nexclude\n\n        \nList of all the token names covered by the \nprefix\n or \nsuffix\n but should\n        not be considered.\n\n        \nArray of strings\n\n    \n\n\n\n\nError object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nprefix\n\n        \nToken name prefix\n\n        \nstring\n\n    \n\n    \n\n        \nsuffix\n\n        \nToken name suffix\n\n        \nstring\n\n    \n\n    \n\n        \ninclude\n\n        \nList of all the token names not covered by the \nprefix\n or \nsuffix\n\n        \nArray of strings\n\n    \n\n    \n\n        \nexclude\n\n        \nList of all the token names covered by the \nprefix\n or \nsuffix\n but should\n        not be considered.\n\n        \nArray of strings\n\n    \n\n\n\n\nReserved object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nToken name (e.g. \nT_IDENTIFIER\n)\n\n        \nThe original token name assigned to the lexical token\n\n        \nReserved token object\n\n    \n\n    \n\n        \nNote: The above row can be applied several times in this object\n\n    \n\n\n\n\nReserved token object table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n    \n\n    \n\n        \nstring (e.g. \nif\n)\n\n        \nInput match\n\n        \nstring (e.g. \nT_IF\n)\n\n        \nNew token name\n\n    \n\n    \n\n        \nNote: The above row can be applied several times in this object\n\n    \n\n\n\n\nIII - Lexical error messages\n\n\nError messages reported by error tokens can be customized to provide meaningful information for the user.\n\n\nJSON structure\n\n\nGlobal key table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \ndefault_message\n\n        \nA default message, used if no specific message is defined for the error token.\n\n        \nstring\n\n        \nGeneral error message. The string can contain \noptional \n        placeholders\n.\n\n        \nYes\n\n    \n\n        \nerror_messages\n\n        \nSpecific message for an error token\n\n        \nObject of \nerror message\n\n        \nCheck table\n\n        \nYes\n\n    \n\n\n\n\nError message object table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n    \n\n    \n\n        \nToken name (e.g. \nT_INVALID_CHAR\n)\n\n        \nPrint error message when the error token is generated.\n\n        \nSpecific error message. The string can contain \noptional\n        placeholders\n\n    \n\n\n\n\nPlaceholders table\n\n\n\n    \n\n        \nPlaceholder\n\n        \nDescription\n\n    \n\n    \n\n        \n${value}\n\n        \nInput value of the lexical token.\n\n    \n\n    \n\n        \n${column}\n\n        \nHorizontal position of the lexical token.\n\n    \n\n    \n\n        \n${line}\n\n        \nLine number where the lexical token is found.\n\n    \n\n    \n\n        \n${filename}\n\n        \nInput file name.",
            "title": "Lexical analysis"
        },
        {
            "location": "/lexical/#lexical-analysis",
            "text": "",
            "title": "Lexical analysis"
        },
        {
            "location": "/lexical/#description",
            "text": "The lexical analysis is the first phase in compiler design where the user input is scanned and converted \ninto a sequence of tokens. The generated lexical tokens are then provided as input to the syntax analyzer.",
            "title": "Description"
        },
        {
            "location": "/lexical/#i-state-machine",
            "text": "A state machine is a graph composed of vertices connected by edges. The graph has a single starting vertex\nand one or more middle or final tokens. Landing on a final vertex means that a new token is created.\nEdges allow input characters to traverse the graph by assigning a letter label to each edge.",
            "title": "I - State machine"
        },
        {
            "location": "/lexical/#json-structure",
            "text": "Global keys table  \n     \n         Key \n         Description \n         Value \n         Required \n     \n     \n         states \n         List of states/vertices of the state machine \n         Array of  state objects \n         Yes \n     \n     \n         transitions \n         List of transitions/edges of the state machine \n         Array of  transition objects \n         Yes \n       State object table  \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         type \n         Type of the state \n         Initial \n         Initial state. Exactly one state must be marked as initial \n         Yes \n     \n     \n         NORMAL \n         Normal state. \n     \n     \n         FINAL \n         Final state. \n     \n     \n         id \n         Unique id for each state \n         0, 1, 2, ... \n         Counting starts from 0 and should be consecutive \n         Yes \n     \n     \n         token \n         Name of the token created when landing on a final state \n         string (e.g.  T_SEMICOLON ) \n         Cannot be a  reserved syntax keyword \n         Only for final states \n     \n     \n         backtrack \n         Backtrack one character in the user input. This is required when the only possible \n        way to know that the token value has ended is by reading a character that is not part of the token \n        value. \n         false \n         Do not backtrack \n         Only for final states \n     \n     \n         true \n         Backtrack \n       Transition object table   \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         from \n         State id, from source \n         0, 1, 2, ... \n         State id must exist and cannot correspond to a final state. \n         Yes \n     \n     \n         to \n         State id, to destination \n         0, 1, 2, ... \n         State id must exist and cannot correspond to the initial state. \n         Yes \n     \n     \n         chars \n         The list of characters that will traverse this edge \n         Array of  char values \n         Check table \n         Yes, cannot be empty. \n       Char values table  \n     \n         Value \n         Description \n     \n     \n         Character (e.g.  = ) \n         A single character \n     \n     \n         EOF \n         End of file \n     \n     \n         NEW_LINE \n         New line:  \\n \n     \n     \n         RETURN \n         Return:  \\r \n     \n     \n         SPACE \n         Single whitespace \n     \n     \n         TAB \n         Single tab:  \\t \n     \n     \n         LOWER_CASE_LETTER \n         A letter from a to z \n     \n     \n         UPPER_CASE_LETTER \n         A letter from A to Z \n     \n     \n         POSITIVE \n         A positive digit from 1 to 9 \n     \n     \n         OTHER \n         Any other character. Every non-final state must have a transition on  OTHER",
            "title": "JSON structure"
        },
        {
            "location": "/lexical/#gui-to-json",
            "text": "",
            "title": "GUI to JSON"
        },
        {
            "location": "/lexical/#introduction",
            "text": "A state machine can get large and it will become hard to keep track of states and transitions. To reduce the\ncomplexity of building state machines, use the  graph.html  tool located under  tools/gui/  in order to\nbuild the machine using a graphical user interface and then export it to JSON.   Note: The tool is written in TypeScript and needs to be compiled before using it.",
            "title": "Introduction"
        },
        {
            "location": "/lexical/#compile-tool",
            "text": "cd tools/gui/ts/\ntsc @compile",
            "title": "Compile tool"
        },
        {
            "location": "/lexical/#ii-lexical-configuration",
            "text": "Lexical configuration allow manipulating and tagging generated tokens.",
            "title": "II - Lexical configuration"
        },
        {
            "location": "/lexical/#json-structure_1",
            "text": "Global keys table  \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         newline \n         Line separator \n         CR \n         \\r \n         Yes \n     \n     \n         LF \n         \\n \n     \n     \n         CRLF \n         \\r\\n \n     \n     \n         ignore \n         List of lexical tokens to be ignored (e.g. code comments) \n         Ignore object \n         Check table \n         Yes \n     \n     \n         error \n         List of lexical tokens resulting in lexical error \n         Error object \n         Check table \n         Yes \n     \n     \n         reserved \n         Manipulate token name once created. This is useful when the user input has a reserved\n        keyword and the state machine marked it as a more general name. \n         Reserved object \n         Check table \n         Yes \n       Ignore object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         prefix \n         Token name prefix \n         string \n     \n     \n         suffix \n         Token name suffix \n         string \n     \n     \n         include \n         List of all the token names not covered by the  prefix  or  suffix \n         Array of strings \n     \n     \n         exclude \n         List of all the token names covered by the  prefix  or  suffix  but should\n        not be considered. \n         Array of strings \n       Error object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         prefix \n         Token name prefix \n         string \n     \n     \n         suffix \n         Token name suffix \n         string \n     \n     \n         include \n         List of all the token names not covered by the  prefix  or  suffix \n         Array of strings \n     \n     \n         exclude \n         List of all the token names covered by the  prefix  or  suffix  but should\n        not be considered. \n         Array of strings \n       Reserved object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         Token name (e.g.  T_IDENTIFIER ) \n         The original token name assigned to the lexical token \n         Reserved token object \n     \n     \n         Note: The above row can be applied several times in this object \n       Reserved token object table  \n     \n         Key \n         Key description \n         Value \n         Value description \n     \n     \n         string (e.g.  if ) \n         Input match \n         string (e.g.  T_IF ) \n         New token name \n     \n     \n         Note: The above row can be applied several times in this object",
            "title": "JSON structure"
        },
        {
            "location": "/lexical/#iii-lexical-error-messages",
            "text": "Error messages reported by error tokens can be customized to provide meaningful information for the user.",
            "title": "III - Lexical error messages"
        },
        {
            "location": "/lexical/#json-structure_2",
            "text": "Global key table  \n     \n         Key \n         Key description \n         Value \n         Value description \n         Required \n     \n     \n         default_message \n         A default message, used if no specific message is defined for the error token. \n         string \n         General error message. The string can contain  optional \n        placeholders . \n         Yes \n     \n         error_messages \n         Specific message for an error token \n         Object of  error message \n         Check table \n         Yes \n       Error message object table  \n     \n         Key \n         Description \n         Value \n     \n     \n         Token name (e.g.  T_INVALID_CHAR ) \n         Print error message when the error token is generated. \n         Specific error message. The string can contain  optional\n        placeholders \n       Placeholders table  \n     \n         Placeholder \n         Description \n     \n     \n         ${value} \n         Input value of the lexical token. \n     \n     \n         ${column} \n         Horizontal position of the lexical token. \n     \n     \n         ${line} \n         Line number where the lexical token is found. \n     \n     \n         ${filename} \n         Input file name.",
            "title": "JSON structure"
        },
        {
            "location": "/syntax/",
            "text": "Syntax analysis\n\n\nDescription\n\n\nSyntax analysis is the second phase in compiler design where the lexical tokens generated by the lexical \nanalyzer are validated against a grammar defining the language syntax. \n\n\nI - Grammar\n\n\nA language syntax is determined by a set of productions forming a grammar. Constructed grammars must \nsatisfy the LL(1) (left to right, leftmost derivation, 1 lookahead) conditions.\n\n\nLL(1) Conditions\n\n\nA - No left recursion\n\n\nExample of a left recursion\n\n\nA -> A a | b\n\n\n\n\nSolution for a left recursion\n\n\nA -> b B\nB -> a B | \u03b5\n\n\n\n\nB - Intersection of First sets in same production must be empty\n\n\nExample of a non-empty intersection of First sets in a same production\n\n\nA -> B C | D E\nB -> F G\nD -> F H\n\n\n\n\nIn the above grammar, First(F) \u2208 First(B) and First(F) \u2208 First(D), therefore First(B) \u2229 First(D) \u2260 {}\n\n\nOne solution for this problem\n\n\nA -> F I\nI -> G C | H E\n\n\n\n\nC - Intersection of First and Follow sets of a non-terminal must be empty\n\n\nExample of a non-empty intersection of First and Follow sets of a non-terminal\n\n\nA -> B a\nB -> a | \u03b5\n\n\n\n\nIn the above grammar, First(B) \u2229 Follow(B) = {a}\n\n\nOne solution for this problem\n\n\nA -> a C\nC -> a | \u03b5\n\n\n\n\nJSON structure\n\n\nTerminals and Non-terminals\n\n\n\n\nNon-terminals must be composed of upper case letters and underscore only. (Cannot be part of\n\nReserved syntax keywords\n)\n\n\nTerminals must begin and end with a single quote. The text in between the single quotes defines the\nlexical token name (case sensitive) and should not contain spaces. (Cannot be part of\n\nReserved syntax keywords\n)\n\n\nEPSILON\n represents an epsilon production.\n\n\nWhitespaces between tokens are delimiters.\n\n\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n    \n\n    \n\n        \nnon-terminal (e.g. \nT_IF\n)\n\n        \nThe non-terminal that can be replaced by its value.\n\n        \nArray of non-terminals string (e.g. \n[\"NT_A NT_B NT_C\"]\n)\n\n    \n\n    \n\n        \nArray of a terminal string (e.g. \n[\"'if'\"]\n)\n\n    \n\n    \n\n        \nArray of an epsilon string (e.g. \n[\"EPSILON\"]\n)\n\n    \n\n    \n\n        \nArray of a mix strings (e.g. \n[\"NT_A NT_B NT_C\", \"'if'\", \"EPSILON\"]\n)\n\n    \n\n    \n\n        \nNote: The above row can be applied several times in this object\n\n    \n\n\n\n\nReserved syntax keyword table\n\n\n\n    \n\n        \nLexical Keyword\n\n    \n\n    \n\n        \n:any\n\n    \n\n    \n\n        \n$\n\n    \n\n\n\n\nII - Syntax error messages\n\n\nWhen the user input does not align with the language grammar, the syntax analyzer will try to recover\nfrom the panic mode and will report customized error messages describing each situation.\n\n\nJSON structure\n\n\nGlobal keys table\n\n\n\n    \n\n        \nKey\n\n        \nDescription\n\n        \nValue\n\n        \nValue description\n\n        \nRequired\n\n    \n\n    \n\n        \ndefault_message\n\n        \nA default message, used if no specific message is defined for a particular situation.\n\n        \nstring\n\n        \nGeneral error message. The string can contain \noptional placeholders\n.\n\n        \nYes\n\n    \n\n    \n\n        \nerror_messages\n\n        \nSpecific message for a particular situation.\n\n        \nArray of \nerror message objects\n\n        \nCheck table\n\n        \nYes\n\n    \n\n\n\n\nError message object table\n\n\n\n    \n\n        \nKey\n\n        \nKey description\n\n        \nValue\n\n        \nValue description\n\n    \n\n    \n\n        \nnon_terminal\n\n        \nNon-terminal expected by the syntax analyzer at a specific location in the input\n\n        \nstring\n\n        \nNon-terminal (e.g. \nT_VAR_NAME\n)\n\n    \n\n    \n\n        \n:any\n\n        \nAny non-terminal\n\n    \n\n    \n\n        \n$\n\n        \nEnd of grammar\n\n    \n\n    \n\n        \nterminal\n\n        \nActual terminal read by the syntax analyzer\n\n        \nstring\n\n        \nTerminal (e.g. \n'equal_sign'\n)\n\n    \n\n    \n\n        \n:any\n\n        \nAny terminal\n\n    \n\n    \n\n        \n$\n\n        \nEnd of file\n\n    \n\n    \n\n        \nmessage\n\n        \nError message\n\n        \nstring\n\n        \nMeaningful message on what was added or unexpected.\n(e.g. 'Missing variable name before the \n        assignment operator at line ${lexical.line}').\nThe string can contain \n        \noptional placeholders\n.\n\n    \n\n\n\n\nPlaceholders table\n\n\n\n    \n\n        \nPlaceholder\n\n        \nDescription\n\n    \n\n    \n\n        \n${lexical[.next|.previous]*.value}\n\n        \nDisplay the value of the token object\n\n    \n\n    \n\n        \n${lexical[.next|.previous]*.column}\n\n        \nDisplay the column number in the line starting from 1\n\n    \n\n    \n\n        \n${lexical[.next|.previous]*.line}\n\n        \nDisplay the line number in the text starting from 1\n\n    \n\n    \n\n        \n${filename}\n\n        \nInput file name.",
            "title": "Syntax analysis"
        },
        {
            "location": "/syntax/#syntax-analysis",
            "text": "",
            "title": "Syntax analysis"
        },
        {
            "location": "/syntax/#description",
            "text": "Syntax analysis is the second phase in compiler design where the lexical tokens generated by the lexical \nanalyzer are validated against a grammar defining the language syntax.",
            "title": "Description"
        },
        {
            "location": "/syntax/#i-grammar",
            "text": "A language syntax is determined by a set of productions forming a grammar. Constructed grammars must \nsatisfy the LL(1) (left to right, leftmost derivation, 1 lookahead) conditions.",
            "title": "I - Grammar"
        },
        {
            "location": "/syntax/#ll1-conditions",
            "text": "",
            "title": "LL(1) Conditions"
        },
        {
            "location": "/syntax/#a-no-left-recursion",
            "text": "Example of a left recursion  A -> A a | b  Solution for a left recursion  A -> b B\nB -> a B | \u03b5",
            "title": "A - No left recursion"
        },
        {
            "location": "/syntax/#b-intersection-of-first-sets-in-same-production-must-be-empty",
            "text": "Example of a non-empty intersection of First sets in a same production  A -> B C | D E\nB -> F G\nD -> F H  In the above grammar, First(F) \u2208 First(B) and First(F) \u2208 First(D), therefore First(B) \u2229 First(D) \u2260 {}  One solution for this problem  A -> F I\nI -> G C | H E",
            "title": "B - Intersection of First sets in same production must be empty"
        },
        {
            "location": "/syntax/#c-intersection-of-first-and-follow-sets-of-a-non-terminal-must-be-empty",
            "text": "Example of a non-empty intersection of First and Follow sets of a non-terminal  A -> B a\nB -> a | \u03b5  In the above grammar, First(B) \u2229 Follow(B) = {a}  One solution for this problem  A -> a C\nC -> a | \u03b5",
            "title": "C - Intersection of First and Follow sets of a non-terminal must be empty"
        },
        {
            "location": "/syntax/#json-structure",
            "text": "Terminals and Non-terminals   Non-terminals must be composed of upper case letters and underscore only. (Cannot be part of Reserved syntax keywords )  Terminals must begin and end with a single quote. The text in between the single quotes defines the\nlexical token name (case sensitive) and should not contain spaces. (Cannot be part of Reserved syntax keywords )  EPSILON  represents an epsilon production.  Whitespaces between tokens are delimiters.   Global keys table  \n     \n         Key \n         Key description \n         Value \n     \n     \n         non-terminal (e.g.  T_IF ) \n         The non-terminal that can be replaced by its value. \n         Array of non-terminals string (e.g.  [\"NT_A NT_B NT_C\"] ) \n     \n     \n         Array of a terminal string (e.g.  [\"'if'\"] ) \n     \n     \n         Array of an epsilon string (e.g.  [\"EPSILON\"] ) \n     \n     \n         Array of a mix strings (e.g.  [\"NT_A NT_B NT_C\", \"'if'\", \"EPSILON\"] ) \n     \n     \n         Note: The above row can be applied several times in this object \n       Reserved syntax keyword table  \n     \n         Lexical Keyword \n     \n     \n         :any \n     \n     \n         $",
            "title": "JSON structure"
        },
        {
            "location": "/syntax/#ii-syntax-error-messages",
            "text": "When the user input does not align with the language grammar, the syntax analyzer will try to recover\nfrom the panic mode and will report customized error messages describing each situation.",
            "title": "II - Syntax error messages"
        },
        {
            "location": "/syntax/#json-structure_1",
            "text": "Global keys table  \n     \n         Key \n         Description \n         Value \n         Value description \n         Required \n     \n     \n         default_message \n         A default message, used if no specific message is defined for a particular situation. \n         string \n         General error message. The string can contain  optional placeholders . \n         Yes \n     \n     \n         error_messages \n         Specific message for a particular situation. \n         Array of  error message objects \n         Check table \n         Yes \n       Error message object table  \n     \n         Key \n         Key description \n         Value \n         Value description \n     \n     \n         non_terminal \n         Non-terminal expected by the syntax analyzer at a specific location in the input \n         string \n         Non-terminal (e.g.  T_VAR_NAME ) \n     \n     \n         :any \n         Any non-terminal \n     \n     \n         $ \n         End of grammar \n     \n     \n         terminal \n         Actual terminal read by the syntax analyzer \n         string \n         Terminal (e.g.  'equal_sign' ) \n     \n     \n         :any \n         Any terminal \n     \n     \n         $ \n         End of file \n     \n     \n         message \n         Error message \n         string \n         Meaningful message on what was added or unexpected. (e.g. 'Missing variable name before the \n        assignment operator at line ${lexical.line}'). The string can contain \n         optional placeholders . \n       Placeholders table  \n     \n         Placeholder \n         Description \n     \n     \n         ${lexical[.next|.previous]*.value} \n         Display the value of the token object \n     \n     \n         ${lexical[.next|.previous]*.column} \n         Display the column number in the line starting from 1 \n     \n     \n         ${lexical[.next|.previous]*.line} \n         Display the line number in the text starting from 1 \n     \n     \n         ${filename} \n         Input file name.",
            "title": "JSON structure"
        },
        {
            "location": "/semantic/",
            "text": "Semantic analysis\n\n\nDescription\n\n\nSemantic anlysis is applied while the syntax analyzer matches the user code with its corresponding grammar\nproductions. The semantic analysis phase introduces action tokens, responsible for performing actions at \nspecific locations in the language grammar.\n\n\nWhat is an action token?\n\n\nAn action token is a special token that can be injected at several locations in the language grammar. \nThe added tokens do not affect the syntax of the language, but they inform the syntax analyzer that at this \nlocation in the grammar a particular action need to be performed. In its turn, the syntax anlyzer\npasses the action to the semantic analyzer which can map each action to its corresponding handler function.\n\n\nWhat is an action handler?\n\n\nAn action handler is a function that is executed by the semantic analyzer when the syntax analyzer encounters\nan action token. When an action hander is called, it will be provided with the last lexical token parsed\nby the syntax analyzer, and the phase number which is usally helpful when an input file needs to be scanned\nmore than one time.\n\n\nI - Add action tokens to the grammar\n\n\nAn action token is represented by a string surrounded by a \n#\n symbol on both sides. Each action token in\nthe grammar reports information about the most recent lexical token that was consumed by the syntax analyzer.\n\n\nFor example, consider the following grammar:\n\n\n{\n    \"...\",\n    \"CLASS_DEFINITION\"  : \"CLASS #newClass# CLASS_NAME #setClassName# CLASS_BODY #endClass#\",\n    \"CLASS\"             : \"'class'\",\n    \"CLASS_NAME\"        : \"'identifier'\",\n    \"CLASS_BODY\"        : \"OPEN_CURLY STATEMENT CLOSE_CURLY\",\n    \"...\"\n}\n\n\n\n\nThe above grammar demonstrates how action tokens help in constructing a class:\n\n\n\n\n#newClass#\n action handler can construct a new instance of a class.\n\n\n#setClassName#\n action handler can set the name of the created class. \n\n\nNotice that the action token is placed right after the lexical token \n'identifier'\n because it\nprovides the handler function with the necessary arguments to identify the exact lexical token.\n\n\n\n\n\n\n#endClass#\n action handler can delete the created class.\n\n\n\n\nII - Create action handlers\n\n\nAn action handler can be registered using the function\nIEasyCC::registerSemanticAction()\n. Here is a simple\ncode showing how the action tokens in the previous example can be registered.\n\n\ntypedef std::vector<std::shared_ptr<ecc::LexicalToken>> Tokens;\n\neasyCC->registerSemanticAction(\"#newClass#\",[&](int phase, Tokens &lexicalVector, int index){\n    newClass = new MyClass();\n});\n\neasyCC->registerSemanticAction(\"#setClassName#\",[&](int phase, Tokens &lexicalVector, int index){\n    newClass->setName(lexicalVector[index]); // Get the last lexical token parsed\n                                             // by the syntax analyzer\n});\n\neasyCC->registerSemanticAction(\"#endClass#\",[&](int phase, Tokens &lexicalVector, int index){\n    delete newClass;\n});",
            "title": "Semantic analysis"
        },
        {
            "location": "/semantic/#semantic-analysis",
            "text": "",
            "title": "Semantic analysis"
        },
        {
            "location": "/semantic/#description",
            "text": "Semantic anlysis is applied while the syntax analyzer matches the user code with its corresponding grammar\nproductions. The semantic analysis phase introduces action tokens, responsible for performing actions at \nspecific locations in the language grammar.",
            "title": "Description"
        },
        {
            "location": "/semantic/#what-is-an-action-token",
            "text": "An action token is a special token that can be injected at several locations in the language grammar. \nThe added tokens do not affect the syntax of the language, but they inform the syntax analyzer that at this \nlocation in the grammar a particular action need to be performed. In its turn, the syntax anlyzer\npasses the action to the semantic analyzer which can map each action to its corresponding handler function.",
            "title": "What is an action token?"
        },
        {
            "location": "/semantic/#what-is-an-action-handler",
            "text": "An action handler is a function that is executed by the semantic analyzer when the syntax analyzer encounters\nan action token. When an action hander is called, it will be provided with the last lexical token parsed\nby the syntax analyzer, and the phase number which is usally helpful when an input file needs to be scanned\nmore than one time.",
            "title": "What is an action handler?"
        },
        {
            "location": "/semantic/#i-add-action-tokens-to-the-grammar",
            "text": "An action token is represented by a string surrounded by a  #  symbol on both sides. Each action token in\nthe grammar reports information about the most recent lexical token that was consumed by the syntax analyzer.  For example, consider the following grammar:  {\n    \"...\",\n    \"CLASS_DEFINITION\"  : \"CLASS #newClass# CLASS_NAME #setClassName# CLASS_BODY #endClass#\",\n    \"CLASS\"             : \"'class'\",\n    \"CLASS_NAME\"        : \"'identifier'\",\n    \"CLASS_BODY\"        : \"OPEN_CURLY STATEMENT CLOSE_CURLY\",\n    \"...\"\n}  The above grammar demonstrates how action tokens help in constructing a class:   #newClass#  action handler can construct a new instance of a class.  #setClassName#  action handler can set the name of the created class.   Notice that the action token is placed right after the lexical token  'identifier'  because it\nprovides the handler function with the necessary arguments to identify the exact lexical token.    #endClass#  action handler can delete the created class.",
            "title": "I - Add action tokens to the grammar"
        },
        {
            "location": "/semantic/#ii-create-action-handlers",
            "text": "An action handler can be registered using the function IEasyCC::registerSemanticAction() . Here is a simple\ncode showing how the action tokens in the previous example can be registered.  typedef std::vector<std::shared_ptr<ecc::LexicalToken>> Tokens;\n\neasyCC->registerSemanticAction(\"#newClass#\",[&](int phase, Tokens &lexicalVector, int index){\n    newClass = new MyClass();\n});\n\neasyCC->registerSemanticAction(\"#setClassName#\",[&](int phase, Tokens &lexicalVector, int index){\n    newClass->setName(lexicalVector[index]); // Get the last lexical token parsed\n                                             // by the syntax analyzer\n});\n\neasyCC->registerSemanticAction(\"#endClass#\",[&](int phase, Tokens &lexicalVector, int index){\n    delete newClass;\n});",
            "title": "II - Create action handlers"
        },
        {
            "location": "/code/",
            "text": "Code generation\n\n\nDescription\n\n\nCode generation is the phase where the the user input is translated into a language that can be \nprocessed by another program or at a lower level.\n\n\nHow to generate code?\n\n\nCode generation can be done inside the action handler function by writing to files or printing on the \nconsole. The phase number, passed as argument to the action handler, can be useful for code generation since\nthe last phase can be dedicated for generating code while the previous ones can validate the input semantics.",
            "title": "Code generation"
        },
        {
            "location": "/code/#code-generation",
            "text": "",
            "title": "Code generation"
        },
        {
            "location": "/code/#description",
            "text": "Code generation is the phase where the the user input is translated into a language that can be \nprocessed by another program or at a lower level.",
            "title": "Description"
        },
        {
            "location": "/code/#how-to-generate-code",
            "text": "Code generation can be done inside the action handler function by writing to files or printing on the \nconsole. The phase number, passed as argument to the action handler, can be useful for code generation since\nthe last phase can be dedicated for generating code while the previous ones can validate the input semantics.",
            "title": "How to generate code?"
        },
        {
            "location": "/example/",
            "text": "Calculator example\n\n\nMotivation\n\n\nCalculator example is a very simple compiler that takes a list of expressions seperated by \n;\n as input, then evalutes each and stores the answers in a file.\n\n\ninput.txt\n\n\n# Expr 1\n1 + 2 * 3;\n\n# Expr 2\n(1 + 2) * 3;\n\n\n\n\noutput.txt\n\n\nExpression result: 7\nExpression result: 9\n\n\n\n\nProject setup\n\n\nThe calculator project can be found under \nexamples/\n in the repo root directory. In this example,\nthe content of the two main files will not be explained because they only provide the command line\ninterface to the executables.\n\n\nStructure\n\n\ncalculator\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 include\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 calculator\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 Calculator.h\n\u251c\u2500\u2500 resources\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 src\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input.txt\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 lexical_config.json\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 lexical_errors.json\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 lexical_state_machine.json\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 syntax_errors.json\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 syntax_grammar.json\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 calculator\n        \u251c\u2500\u2500 Calculator.cpp\n        \u251c\u2500\u2500 maindev.cpp\n        \u2514\u2500\u2500 mainpro.cpp\n\n\n\n\n\nCMakeLists.txt\n\n\nRefer to the \nhome page\n for the sample \nCMakeLists.txt\n\n\ncmake_minimum_required(VERSION 3.5)\nproject(calculator)\nset(CMAKE_VERBOSE_MAKEFILE ON)\nset(CALCULATOR_DEV_EXEC \"calculatordev\")\nset(CALCULATOR_PRO_EXEC \"calculator\")\n\n# Add easycc CMakeLists.txt to build it automatically\nadd_subdirectory(${PROJECT_SOURCE_DIR}/../../ ${PROJECT_BINARY_DIR}/EasyCC-CPP)\n\n# Compile with -std=c++11 flag\nadd_compile_options(-std=c++11)\n\n# Configure directory of output file\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# Include calculator header files (e.g. same as -I flag)\ninclude_directories(include)\ninclude_directories(../../include)\ninclude_directories(../../thirdparty/rapidjson/include)\n\n# Store cpp files in a variable\nfile(GLOB_RECURSE CALC_PROJECT_SOURCE_FILES src/*/*.cpp)\nlist(REMOVE_ITEM CALC_PROJECT_SOURCE_FILES\n        \"${PROJECT_SOURCE_DIR}/src/calculator/maindev.cpp\"\n        \"${PROJECT_SOURCE_DIR}/src/calculator/mainpro.cpp\")\n\n# Add the executables\nadd_executable(${CALCULATOR_DEV_EXEC} ${CALC_PROJECT_SOURCE_FILES} src/calculator/maindev.cpp)\nadd_executable(${CALCULATOR_PRO_EXEC} ${CALC_PROJECT_SOURCE_FILES} src/calculator/mainpro.cpp)\n\n# Link library to the executable\ntarget_link_libraries(${CALCULATOR_DEV_EXEC} easyccdev)\ntarget_link_libraries(${CALCULATOR_PRO_EXEC} easyccpro)\n\n\n\n\nLexical analysis\n\n\nI - lexical_state_machine.json\n\n\nAn image of the state machine is provided \nbelow\n.\n\nRefer to the \nstate machine section\n for more details.\n\n\n{\n    \"states\": [\n        {\n            \"type\": \"INITIAL\",\n            \"id\": 0\n        },\n        {\n            \"type\": \"NORMAL\",\n            \"id\": 1\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 2,\n            \"token\": \"T_INTEGER\",\n            \"backtrack\": true\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 3,\n            \"token\": \"T_PLUS\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 4,\n            \"token\": \"T_MINUS\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 5,\n            \"token\": \"T_MULTIPLY\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 6,\n            \"token\": \"T_DIVIDE\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 7,\n            \"token\": \"T_SEMICOLON\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 8,\n            \"token\": \"T_INVALID_CHAR\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 9,\n            \"token\": \"T_INTEGER\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 10,\n            \"token\": \"T_OPEN_PAR\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 11,\n            \"token\": \"T_CLOSE_PAR\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"NORMAL\",\n            \"id\": 12\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 13,\n            \"token\": \"T_COMMENT\",\n            \"backtrack\": true\n        }\n    ],\n    \"transitions\": [\n        {\n            \"from\": 0,\n            \"to\": 0,\n            \"chars\": [\"SPACE\",\"RETURN\",\"TAB\",\"NEW_LINE\",\"EOF\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 1,\n            \"chars\": [\"POSITIVE\"]\n        },\n        {\n            \"from\": 1,\n            \"to\": 1,\n            \"chars\": [\"POSITIVE\",\"0\"]\n        },\n        {\n            \"from\": 1,\n            \"to\": 2,\n            \"chars\": [\"OTHER\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 3,\n            \"chars\": [\"+\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 4,\n            \"chars\": [\"-\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 5,\n            \"chars\": [\"*\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 6,\n            \"chars\": [\"/\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 7,\n            \"chars\": [\";\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 8,\n            \"chars\": [\"OTHER\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 9,\n            \"chars\": [\"0\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 10,\n            \"chars\": [\"(\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 11,\n            \"chars\": [\")\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 12,\n            \"chars\": [\"#\"]\n        },\n        {\n            \"from\": 12,\n            \"to\": 12,\n            \"chars\": [\"OTHER\"]\n        },\n        {\n            \"from\": 12,\n            \"to\": 13,\n            \"chars\": [\"NEW_LINE\",\"EOF\"]\n        }\n    ]\n}\n\n\n\n\nThe graph below was generated by the tool described in the \n\nlexical analysis page\n.\n\n\n\nII - lexical_config.json\n\n\n\n\nThe lexical tokens \nT_COMMENT\n are ignored, so they will not be passed to the syntax analyzer.\n\n\nThe lexical tokens \nT_INVALID_CHAR\n are marked as error tokens and will report \n\nerror messages\n once created.\n\n\nThe lexical tokens \nT_INTEGER\n which have the value \n0\n will be renamed to \nT_ZERO\n.\n\n\n\n\nRefer to the \nlexical configuration section\n for more details.\n\n\n{\n    \"newline\": \"LF\",\n\n    \"ignore\": {\n        \"prefix\": \"\",\n        \"suffix\": \"\",\n        \"include\": [\"T_COMMENT\"],\n        \"exclude\": []\n    },\n\n    \"error\": {\n        \"prefix\": \"T_INVALID_CHAR\",\n        \"suffix\": \"\",\n        \"include\": [],\n        \"exclude\": []\n    },\n\n    \"reserved\": {\n        \"T_INTEGER\" : {\n            \"0\" : \"T_ZERO\"\n        }\n    }\n}\n\n\n\n\nIII - lexical_errors.json\n\n\n\n\nDefault message is printed if no message was assigned to an error token (In this case, default message is\nnever printed).\n\n\nT_INVALID_CHAR\n will print its assigned message once created.\n\n\nPlaceholders are replaced with their corresponding values. Check the full list of \n\nlexical error message placeholders\n.\n\n\n\n\nRefer to the \nlexical error message section\n for \nmore details.\n\n\n{\n    \"default_message\": \"${filename}: Error found '${value}' at line ${line} and column ${column}\",\n    \"error_messages\": {\n        \"T_INVALID_CHAR\" : \"${filename}: Invalid character '${value}' found at line ${line} and column ${column}\"\n    }\n}\n\n\n\n\nSyntax analysis\n\n\nI - syntax_grammar.json\n\n\n\n\nThe grammar takes care of the operator precedence.\n\n\nNotice the 4 different types of items in the grammar:\n\n\nTerminal\n\n\nNon-terminal\n\n\nEpsilon\n\n\nAction token\n\n\n\n\n\n\n\n\nRefer to the \ngrammar section\n for more details.\n\n\n{\n    \"S\"             : [\"A T_SEMICOLON #print# S #end#\",\"EPSILON\"],\n    \"A\"             : [\"C B\"],\n    \"B\"             : [\"EPSILON\",\"T_PLUS C #plus# B\",\"T_MINUS C #minus# B\"],\n    \"C\"             : [\"E D\"],\n    \"D\"             : [\"EPSILON\",\"T_MULTIPLY E #multiply# D\",\"T_DIVIDE #divide# E D\"],\n    \"E\"             : [\"T_OPEN_PAR A T_CLOSE_PAR\",\"NUMBER #push#\"],\n    \"NUMBER\"        : [\"'T_INTEGER'\",\"'T_ZERO'\"],\n    \"T_PLUS\"        : [\"'T_PLUS'\"],\n    \"T_MINUS\"       : [\"'T_MINUS'\"],\n    \"T_MULTIPLY\"    : [\"'T_MULTIPLY'\"],\n    \"T_DIVIDE\"      : [\"'T_DIVIDE'\"],\n    \"T_OPEN_PAR\"    : [\"'T_OPEN_PAR'\"],\n    \"T_CLOSE_PAR\"   : [\"'T_CLOSE_PAR'\"],\n    \"T_SEMICOLON\"   : [\"'T_SEMICOLON'\"]\n}\n\n\n\n\nII - syntax_errors.json\n\n\n\n\nDefault message is printed if the syntax analyzer is in panic mode and did not find an error message\nassociated to the situation.\n\n\nIf the syntax analyzer was expecting anything \n:any\n but a \nT_INTEGER\n, then it will print the\ncorresponding error message.\n\n\nSimilarly, if the syntax was expecting anything \n:any\n but a \nT_ZERO\n, then it will print the \ncorresponding error message.\n\n\nPlaceholders are replaced with their corresponding values. Check the full list of \n\nsyntax error message placeholders\n.\n\n\nFor the list of special values for \nnon_terminal\n and \nterminal\n keys, check the table in the \n\nsyntax error messages section\n.\n\n\n\n\nRefer to the \nsyntax error messages section\n for more \ndetails.\n\n\n{\n    \"default_message\": \"${filename}: Error found: ${lexical.value} at line ${lexical.line} and column ${lexical.column}\",\n    \"error_messages\": [\n        {\n            \"non_terminal\": \":any\",\n            \"terminal\": \"T_INTEGER\",\n            \"message\": \"${filename}: Expecting a symbol before '${lexical.value}' at line ${lexical.line} and column ${lexical.column}\"\n        },\n        {\n            \"non_terminal\": \":any\",\n            \"terminal\": \"T_ZERO\",\n            \"message\": \"${filename}: Expecting a symbol before '0' at line ${lexical.line} and column ${lexical.column}\"\n        }\n    ]\n}\n\n\n\n\nSemantic analysis & Code generation\n\n\nCalculator.cpp\n\n\nCalculator::compile()\n\n\n\n\nInitialize handler (explained \nbelow\n)\n\n\nOpen output file for code generation.\n\n\nConfigure EasyCC library.\n\n\nsetParsingPhase(0)\n: sets the phase value which is passed as argument to action handlers. \nFor languages that require analyzing the syntax mutliple times, the phase value can be set to a counter\nthat increments on every iteration.\n\n\nsetSilentSyntaxErrorMessages(false)\n: If a language is parsed several times, then only one iteration\nneeds to report syntax errors. \n\n\nsetSilentSemanticEvent(false)\n: If \ntrue\n is passed as argument, then no action handlers will be\nexecuted.\n\n\nsetOnSyntaxError(function)\n: Register a function that is executed when a syntax error occurs. In the\ncalculator example, if a syntax error occurs the program writes a message to the output file and closes it.\n\n\n\n\n\n\nLoop on input files and compile them.\n\n\n\n\nint Calculator::compile(std::vector<std::string> inputFiles, std::string outputFile) {\n\n    // Initialize semantic action handlers\n    initHandlers();\n\n    // Set output file\n    m_output.open(outputFile);\n\n    // Configure easycc\n    m_easyCC->setParsingPhase(0);\n    m_easyCC->setSilentSyntaxErrorMessages(false);\n    m_easyCC->setSilentSemanticEvents(false);\n    m_easyCC->setOnSyntaxError([&](){\n        m_easyCC->setSilentSemanticEvents(true);\n        m_output << \"Error evaluating expression\" << std::endl;\n        m_output.close();\n    });\n\n    // Compile all files\n    for(std::string fileName : inputFiles) {\n        int code = m_easyCC->compile(fileName);\n        if(code != ecc::IEasyCC::OK_CODE) {\n            return code;\n        }\n    }\n    return 0;\n}\n\n\n\n\nCalculator::initHandlers()\n\n\n\n\nRegister an action handler for \n#push#\n\n\nOnce a number is parsed, push it to the stack\n\n\n\n\n\n\nRegister an action handler for \n#plus#\n\n\nOnce a \n+\n is parsed, pop the last two numbers and push the result to the stack\n\n\n\n\n\n\nRegister an action handler for \n#minus#\n\n\nOnce a \n-\n is parsed, pop the last two numbers and push the result to the stack\n\n\n\n\n\n\nRegister an action handler for \n#multiply#\n\n\nOnce a \n*\n is parsed, pop the last two numbers and push the result to the stack\n\n\n\n\n\n\nRegister an action handler for \n#divide#\n\n\nOnce a \n/\n is parsed, pop the last two numbers and push the result to the stack\n\n\n\n\n\n\nRegister an action handler for \n#print#\n\n\nWrite final result to the file at the end of each expression.\n\n\n\n\n\n\nRegister an action handler for \n#end#\n\n\nClose the output file at the end of the input file\n\n\n\n\n\n\n\n\nvoid Calculator::initHandlers() {\n    /**\n     * Register 'push' semantic action\n     * Every time an integer is read it will be pushed into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#push#\",[&](int phase, Tokens &lexicalVector, int index){\n        m_operands.push(std::stoi(lexicalVector[index]->getValue()));\n    });\n\n    /**\n     * Register 'plus' semantic action\n     * Once the two operands are pushed, add them and push the result into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#plus#\",[&](int phase, Tokens &lexicalVector, int index){\n        int popR = m_operands.top();\n        m_operands.pop();\n        int popL = m_operands.top();\n        m_operands.pop();\n        m_operands.push(popL + popR);\n    });\n\n    /**\n     * Register 'minus' semantic action\n     * Once the two operands are pushed, subtract them and push the result into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#minus#\",[&](int phase, Tokens &lexicalVector, int index){\n        int popR = m_operands.top();\n        m_operands.pop();\n        int popL = m_operands.top();\n        m_operands.pop();\n        m_operands.push(popL - popR);\n    });\n\n    /**\n     * Register 'multiply' semantic action\n     * Once the two operands are pushed, multiply them and push the result into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#multiply#\",[&](int phase, Tokens &lexicalVector, int index){\n        int popR = m_operands.top();\n        m_operands.pop();\n        int popL = m_operands.top();\n        m_operands.pop();\n        m_operands.push(popL * popR);\n    });\n\n    /**\n     * Register 'divide' semantic action\n     * Once the two operands are pushed, divide them and push the result into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#divide#\",[&](int phase, Tokens &lexicalVector, int index){\n        int popR = m_operands.top();\n        m_operands.pop();\n        int popL = m_operands.top();\n        m_operands.pop();\n        m_operands.push(popL / popR);\n    });\n\n    /**\n     * Register 'print' semantic action\n     * At the end of the expression, output the result to a file\n     */\n    m_easyCC->registerSemanticAction(\"#print#\",[&](int phase, Tokens &lexicalVector, int index){\n        m_output << \"Expression result: \" << m_operands.top() << std::endl;\n        m_operands.pop();\n    });\n\n    /**\n     * Register 'end' semantic action\n     * Once the end of file is reached, close the output file\n     */\n    m_easyCC->registerSemanticAction(\"#end#\",[&](int phase, Tokens &lexicalVector, int index){\n        m_output.close();\n    });\n}\n\n\n\n\nBuild the Calculator project\n\n\ncmake\n\n\ncmake . \\\n    -DSYNTAX_ERRORS=\"${PWD}/resources/src/syntax_errors.json\"\\\n    -DSYNTAX_GRAMMAR=\"${PWD}/resources/src/syntax_grammar.json\"\\\n    -DLEXICAL_ERRORS=\"${PWD}/resources/src/lexical_errors.json\"\\\n    -DLEXICAL_CONFIG=\"${PWD}/resources/src/lexical_config.json\"\\\n    -DLEXICAL_STATE_MACHINE=\"${PWD}/resources/src/lexical_state_machine.json\"\n\n\n\n\n\nmake \ncalculator\n production mode\n\n\n# Generate header file\nmake generate_files\n\n# Run cmake again (section above)\n# cmake . ...\n\n# Build project\nmake calculator\n\n\n\n\n\nmake \ncalculator\n developer mode\n\n\nmake calculatordev\n\n\n\n\nUse Calculator compiler\n\n\nProduction mode\n\n\n./bin/calculator resources/src/input.txt -o output.txt\n\n\n\n\nDeveloper mode\n\n\n./bin/calculatordev \\\n    -s resources/src/lexical_state_machine.json \\\n    -c resources/src/lexical_config.json \\\n    -e resources/src/lexical_errors.json \\\n    -g resources/src/syntax_grammar.json \\\n    -E resources/src/syntax_errors.json \\\n    -o /tmp/result.txt \\\n    -v \\\n    resources/src/input.txt",
            "title": "Calculator example"
        },
        {
            "location": "/example/#calculator-example",
            "text": "",
            "title": "Calculator example"
        },
        {
            "location": "/example/#motivation",
            "text": "Calculator example is a very simple compiler that takes a list of expressions seperated by  ;  as input, then evalutes each and stores the answers in a file.",
            "title": "Motivation"
        },
        {
            "location": "/example/#inputtxt",
            "text": "# Expr 1\n1 + 2 * 3;\n\n# Expr 2\n(1 + 2) * 3;",
            "title": "input.txt"
        },
        {
            "location": "/example/#outputtxt",
            "text": "Expression result: 7\nExpression result: 9",
            "title": "output.txt"
        },
        {
            "location": "/example/#project-setup",
            "text": "The calculator project can be found under  examples/  in the repo root directory. In this example,\nthe content of the two main files will not be explained because they only provide the command line\ninterface to the executables.",
            "title": "Project setup"
        },
        {
            "location": "/example/#structure",
            "text": "calculator\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 include\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 calculator\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 Calculator.h\n\u251c\u2500\u2500 resources\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 src\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input.txt\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 lexical_config.json\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 lexical_errors.json\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 lexical_state_machine.json\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 syntax_errors.json\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 syntax_grammar.json\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 calculator\n        \u251c\u2500\u2500 Calculator.cpp\n        \u251c\u2500\u2500 maindev.cpp\n        \u2514\u2500\u2500 mainpro.cpp",
            "title": "Structure"
        },
        {
            "location": "/example/#cmakeliststxt",
            "text": "Refer to the  home page  for the sample  CMakeLists.txt  cmake_minimum_required(VERSION 3.5)\nproject(calculator)\nset(CMAKE_VERBOSE_MAKEFILE ON)\nset(CALCULATOR_DEV_EXEC \"calculatordev\")\nset(CALCULATOR_PRO_EXEC \"calculator\")\n\n# Add easycc CMakeLists.txt to build it automatically\nadd_subdirectory(${PROJECT_SOURCE_DIR}/../../ ${PROJECT_BINARY_DIR}/EasyCC-CPP)\n\n# Compile with -std=c++11 flag\nadd_compile_options(-std=c++11)\n\n# Configure directory of output file\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)\n\n# Include calculator header files (e.g. same as -I flag)\ninclude_directories(include)\ninclude_directories(../../include)\ninclude_directories(../../thirdparty/rapidjson/include)\n\n# Store cpp files in a variable\nfile(GLOB_RECURSE CALC_PROJECT_SOURCE_FILES src/*/*.cpp)\nlist(REMOVE_ITEM CALC_PROJECT_SOURCE_FILES\n        \"${PROJECT_SOURCE_DIR}/src/calculator/maindev.cpp\"\n        \"${PROJECT_SOURCE_DIR}/src/calculator/mainpro.cpp\")\n\n# Add the executables\nadd_executable(${CALCULATOR_DEV_EXEC} ${CALC_PROJECT_SOURCE_FILES} src/calculator/maindev.cpp)\nadd_executable(${CALCULATOR_PRO_EXEC} ${CALC_PROJECT_SOURCE_FILES} src/calculator/mainpro.cpp)\n\n# Link library to the executable\ntarget_link_libraries(${CALCULATOR_DEV_EXEC} easyccdev)\ntarget_link_libraries(${CALCULATOR_PRO_EXEC} easyccpro)",
            "title": "CMakeLists.txt"
        },
        {
            "location": "/example/#lexical-analysis",
            "text": "",
            "title": "Lexical analysis"
        },
        {
            "location": "/example/#i-lexical_state_machinejson",
            "text": "An image of the state machine is provided  below . \nRefer to the  state machine section  for more details.  {\n    \"states\": [\n        {\n            \"type\": \"INITIAL\",\n            \"id\": 0\n        },\n        {\n            \"type\": \"NORMAL\",\n            \"id\": 1\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 2,\n            \"token\": \"T_INTEGER\",\n            \"backtrack\": true\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 3,\n            \"token\": \"T_PLUS\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 4,\n            \"token\": \"T_MINUS\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 5,\n            \"token\": \"T_MULTIPLY\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 6,\n            \"token\": \"T_DIVIDE\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 7,\n            \"token\": \"T_SEMICOLON\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 8,\n            \"token\": \"T_INVALID_CHAR\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 9,\n            \"token\": \"T_INTEGER\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 10,\n            \"token\": \"T_OPEN_PAR\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 11,\n            \"token\": \"T_CLOSE_PAR\",\n            \"backtrack\": false\n        },\n        {\n            \"type\": \"NORMAL\",\n            \"id\": 12\n        },\n        {\n            \"type\": \"FINAL\",\n            \"id\": 13,\n            \"token\": \"T_COMMENT\",\n            \"backtrack\": true\n        }\n    ],\n    \"transitions\": [\n        {\n            \"from\": 0,\n            \"to\": 0,\n            \"chars\": [\"SPACE\",\"RETURN\",\"TAB\",\"NEW_LINE\",\"EOF\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 1,\n            \"chars\": [\"POSITIVE\"]\n        },\n        {\n            \"from\": 1,\n            \"to\": 1,\n            \"chars\": [\"POSITIVE\",\"0\"]\n        },\n        {\n            \"from\": 1,\n            \"to\": 2,\n            \"chars\": [\"OTHER\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 3,\n            \"chars\": [\"+\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 4,\n            \"chars\": [\"-\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 5,\n            \"chars\": [\"*\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 6,\n            \"chars\": [\"/\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 7,\n            \"chars\": [\";\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 8,\n            \"chars\": [\"OTHER\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 9,\n            \"chars\": [\"0\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 10,\n            \"chars\": [\"(\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 11,\n            \"chars\": [\")\"]\n        },\n        {\n            \"from\": 0,\n            \"to\": 12,\n            \"chars\": [\"#\"]\n        },\n        {\n            \"from\": 12,\n            \"to\": 12,\n            \"chars\": [\"OTHER\"]\n        },\n        {\n            \"from\": 12,\n            \"to\": 13,\n            \"chars\": [\"NEW_LINE\",\"EOF\"]\n        }\n    ]\n}  The graph below was generated by the tool described in the  lexical analysis page .",
            "title": "I - lexical_state_machine.json"
        },
        {
            "location": "/example/#ii-lexical_configjson",
            "text": "The lexical tokens  T_COMMENT  are ignored, so they will not be passed to the syntax analyzer.  The lexical tokens  T_INVALID_CHAR  are marked as error tokens and will report  error messages  once created.  The lexical tokens  T_INTEGER  which have the value  0  will be renamed to  T_ZERO .   Refer to the  lexical configuration section  for more details.  {\n    \"newline\": \"LF\",\n\n    \"ignore\": {\n        \"prefix\": \"\",\n        \"suffix\": \"\",\n        \"include\": [\"T_COMMENT\"],\n        \"exclude\": []\n    },\n\n    \"error\": {\n        \"prefix\": \"T_INVALID_CHAR\",\n        \"suffix\": \"\",\n        \"include\": [],\n        \"exclude\": []\n    },\n\n    \"reserved\": {\n        \"T_INTEGER\" : {\n            \"0\" : \"T_ZERO\"\n        }\n    }\n}",
            "title": "II - lexical_config.json"
        },
        {
            "location": "/example/#iii-lexical_errorsjson",
            "text": "Default message is printed if no message was assigned to an error token (In this case, default message is\nnever printed).  T_INVALID_CHAR  will print its assigned message once created.  Placeholders are replaced with their corresponding values. Check the full list of  lexical error message placeholders .   Refer to the  lexical error message section  for \nmore details.  {\n    \"default_message\": \"${filename}: Error found '${value}' at line ${line} and column ${column}\",\n    \"error_messages\": {\n        \"T_INVALID_CHAR\" : \"${filename}: Invalid character '${value}' found at line ${line} and column ${column}\"\n    }\n}",
            "title": "III - lexical_errors.json"
        },
        {
            "location": "/example/#syntax-analysis",
            "text": "",
            "title": "Syntax analysis"
        },
        {
            "location": "/example/#i-syntax_grammarjson",
            "text": "The grammar takes care of the operator precedence.  Notice the 4 different types of items in the grammar:  Terminal  Non-terminal  Epsilon  Action token     Refer to the  grammar section  for more details.  {\n    \"S\"             : [\"A T_SEMICOLON #print# S #end#\",\"EPSILON\"],\n    \"A\"             : [\"C B\"],\n    \"B\"             : [\"EPSILON\",\"T_PLUS C #plus# B\",\"T_MINUS C #minus# B\"],\n    \"C\"             : [\"E D\"],\n    \"D\"             : [\"EPSILON\",\"T_MULTIPLY E #multiply# D\",\"T_DIVIDE #divide# E D\"],\n    \"E\"             : [\"T_OPEN_PAR A T_CLOSE_PAR\",\"NUMBER #push#\"],\n    \"NUMBER\"        : [\"'T_INTEGER'\",\"'T_ZERO'\"],\n    \"T_PLUS\"        : [\"'T_PLUS'\"],\n    \"T_MINUS\"       : [\"'T_MINUS'\"],\n    \"T_MULTIPLY\"    : [\"'T_MULTIPLY'\"],\n    \"T_DIVIDE\"      : [\"'T_DIVIDE'\"],\n    \"T_OPEN_PAR\"    : [\"'T_OPEN_PAR'\"],\n    \"T_CLOSE_PAR\"   : [\"'T_CLOSE_PAR'\"],\n    \"T_SEMICOLON\"   : [\"'T_SEMICOLON'\"]\n}",
            "title": "I - syntax_grammar.json"
        },
        {
            "location": "/example/#ii-syntax_errorsjson",
            "text": "Default message is printed if the syntax analyzer is in panic mode and did not find an error message\nassociated to the situation.  If the syntax analyzer was expecting anything  :any  but a  T_INTEGER , then it will print the\ncorresponding error message.  Similarly, if the syntax was expecting anything  :any  but a  T_ZERO , then it will print the \ncorresponding error message.  Placeholders are replaced with their corresponding values. Check the full list of  syntax error message placeholders .  For the list of special values for  non_terminal  and  terminal  keys, check the table in the  syntax error messages section .   Refer to the  syntax error messages section  for more \ndetails.  {\n    \"default_message\": \"${filename}: Error found: ${lexical.value} at line ${lexical.line} and column ${lexical.column}\",\n    \"error_messages\": [\n        {\n            \"non_terminal\": \":any\",\n            \"terminal\": \"T_INTEGER\",\n            \"message\": \"${filename}: Expecting a symbol before '${lexical.value}' at line ${lexical.line} and column ${lexical.column}\"\n        },\n        {\n            \"non_terminal\": \":any\",\n            \"terminal\": \"T_ZERO\",\n            \"message\": \"${filename}: Expecting a symbol before '0' at line ${lexical.line} and column ${lexical.column}\"\n        }\n    ]\n}",
            "title": "II - syntax_errors.json"
        },
        {
            "location": "/example/#semantic-analysis-code-generation",
            "text": "",
            "title": "Semantic analysis &amp; Code generation"
        },
        {
            "location": "/example/#calculatorcpp",
            "text": "",
            "title": "Calculator.cpp"
        },
        {
            "location": "/example/#calculatorcompile",
            "text": "Initialize handler (explained  below )  Open output file for code generation.  Configure EasyCC library.  setParsingPhase(0) : sets the phase value which is passed as argument to action handlers. \nFor languages that require analyzing the syntax mutliple times, the phase value can be set to a counter\nthat increments on every iteration.  setSilentSyntaxErrorMessages(false) : If a language is parsed several times, then only one iteration\nneeds to report syntax errors.   setSilentSemanticEvent(false) : If  true  is passed as argument, then no action handlers will be\nexecuted.  setOnSyntaxError(function) : Register a function that is executed when a syntax error occurs. In the\ncalculator example, if a syntax error occurs the program writes a message to the output file and closes it.    Loop on input files and compile them.   int Calculator::compile(std::vector<std::string> inputFiles, std::string outputFile) {\n\n    // Initialize semantic action handlers\n    initHandlers();\n\n    // Set output file\n    m_output.open(outputFile);\n\n    // Configure easycc\n    m_easyCC->setParsingPhase(0);\n    m_easyCC->setSilentSyntaxErrorMessages(false);\n    m_easyCC->setSilentSemanticEvents(false);\n    m_easyCC->setOnSyntaxError([&](){\n        m_easyCC->setSilentSemanticEvents(true);\n        m_output << \"Error evaluating expression\" << std::endl;\n        m_output.close();\n    });\n\n    // Compile all files\n    for(std::string fileName : inputFiles) {\n        int code = m_easyCC->compile(fileName);\n        if(code != ecc::IEasyCC::OK_CODE) {\n            return code;\n        }\n    }\n    return 0;\n}",
            "title": "Calculator::compile()"
        },
        {
            "location": "/example/#calculatorinithandlers",
            "text": "Register an action handler for  #push#  Once a number is parsed, push it to the stack    Register an action handler for  #plus#  Once a  +  is parsed, pop the last two numbers and push the result to the stack    Register an action handler for  #minus#  Once a  -  is parsed, pop the last two numbers and push the result to the stack    Register an action handler for  #multiply#  Once a  *  is parsed, pop the last two numbers and push the result to the stack    Register an action handler for  #divide#  Once a  /  is parsed, pop the last two numbers and push the result to the stack    Register an action handler for  #print#  Write final result to the file at the end of each expression.    Register an action handler for  #end#  Close the output file at the end of the input file     void Calculator::initHandlers() {\n    /**\n     * Register 'push' semantic action\n     * Every time an integer is read it will be pushed into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#push#\",[&](int phase, Tokens &lexicalVector, int index){\n        m_operands.push(std::stoi(lexicalVector[index]->getValue()));\n    });\n\n    /**\n     * Register 'plus' semantic action\n     * Once the two operands are pushed, add them and push the result into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#plus#\",[&](int phase, Tokens &lexicalVector, int index){\n        int popR = m_operands.top();\n        m_operands.pop();\n        int popL = m_operands.top();\n        m_operands.pop();\n        m_operands.push(popL + popR);\n    });\n\n    /**\n     * Register 'minus' semantic action\n     * Once the two operands are pushed, subtract them and push the result into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#minus#\",[&](int phase, Tokens &lexicalVector, int index){\n        int popR = m_operands.top();\n        m_operands.pop();\n        int popL = m_operands.top();\n        m_operands.pop();\n        m_operands.push(popL - popR);\n    });\n\n    /**\n     * Register 'multiply' semantic action\n     * Once the two operands are pushed, multiply them and push the result into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#multiply#\",[&](int phase, Tokens &lexicalVector, int index){\n        int popR = m_operands.top();\n        m_operands.pop();\n        int popL = m_operands.top();\n        m_operands.pop();\n        m_operands.push(popL * popR);\n    });\n\n    /**\n     * Register 'divide' semantic action\n     * Once the two operands are pushed, divide them and push the result into the stack\n     */\n    m_easyCC->registerSemanticAction(\"#divide#\",[&](int phase, Tokens &lexicalVector, int index){\n        int popR = m_operands.top();\n        m_operands.pop();\n        int popL = m_operands.top();\n        m_operands.pop();\n        m_operands.push(popL / popR);\n    });\n\n    /**\n     * Register 'print' semantic action\n     * At the end of the expression, output the result to a file\n     */\n    m_easyCC->registerSemanticAction(\"#print#\",[&](int phase, Tokens &lexicalVector, int index){\n        m_output << \"Expression result: \" << m_operands.top() << std::endl;\n        m_operands.pop();\n    });\n\n    /**\n     * Register 'end' semantic action\n     * Once the end of file is reached, close the output file\n     */\n    m_easyCC->registerSemanticAction(\"#end#\",[&](int phase, Tokens &lexicalVector, int index){\n        m_output.close();\n    });\n}",
            "title": "Calculator::initHandlers()"
        },
        {
            "location": "/example/#build-the-calculator-project",
            "text": "",
            "title": "Build the Calculator project"
        },
        {
            "location": "/example/#cmake",
            "text": "cmake . \\\n    -DSYNTAX_ERRORS=\"${PWD}/resources/src/syntax_errors.json\"\\\n    -DSYNTAX_GRAMMAR=\"${PWD}/resources/src/syntax_grammar.json\"\\\n    -DLEXICAL_ERRORS=\"${PWD}/resources/src/lexical_errors.json\"\\\n    -DLEXICAL_CONFIG=\"${PWD}/resources/src/lexical_config.json\"\\\n    -DLEXICAL_STATE_MACHINE=\"${PWD}/resources/src/lexical_state_machine.json\"",
            "title": "cmake"
        },
        {
            "location": "/example/#make-calculator-production-mode",
            "text": "# Generate header file\nmake generate_files\n\n# Run cmake again (section above)\n# cmake . ...\n\n# Build project\nmake calculator",
            "title": "make calculator production mode"
        },
        {
            "location": "/example/#make-calculator-developer-mode",
            "text": "make calculatordev",
            "title": "make calculator developer mode"
        },
        {
            "location": "/example/#use-calculator-compiler",
            "text": "",
            "title": "Use Calculator compiler"
        },
        {
            "location": "/example/#production-mode",
            "text": "./bin/calculator resources/src/input.txt -o output.txt",
            "title": "Production mode"
        },
        {
            "location": "/example/#developer-mode",
            "text": "./bin/calculatordev \\\n    -s resources/src/lexical_state_machine.json \\\n    -c resources/src/lexical_config.json \\\n    -e resources/src/lexical_errors.json \\\n    -g resources/src/syntax_grammar.json \\\n    -E resources/src/syntax_errors.json \\\n    -o /tmp/result.txt \\\n    -v \\\n    resources/src/input.txt",
            "title": "Developer mode"
        }
    ]
}